{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a136ce0b",
   "metadata": {},
   "source": [
    "# Train Test Split: Splitting Consumption Timeseries\n",
    "\n",
    "The train/test split function as is, is starting to become overcrowded. While some requirements are shared by the MIMIC-III and smartmeter dataset, we need to investigate, whether it makes sense to split the function.\n",
    "\n",
    "Additionally, we want to add the following split functionalities:\n",
    "* Split by date\n",
    "* Split by time ratio\n",
    "* Split by feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee93e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.mimic import get_sample_size\n",
    "import numpy as np\n",
    "import pdb\n",
    "from utils.IO import *\n",
    "from sklearn import model_selection\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787c0cb",
   "metadata": {},
   "source": [
    "## I. Data\n",
    "\n",
    "To test our implementation, we will need to construct example data frames. \n",
    "\n",
    "We need frames representing:\n",
    "* Dictionary with subframes of variable length\n",
    "* Dictionary with subframes of same frames\n",
    "* Frame with datetime index\n",
    "* Dictionary with datetime indexed frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f5de5c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>holiday</th>\n",
       "      <th>precipType</th>\n",
       "      <th>icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>pressure</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-12 06:30:00</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>no holiday</td>\n",
       "      <td>rain</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>12.38</td>\n",
       "      <td>259.0</td>\n",
       "      <td>10.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1002.72</td>\n",
       "      <td>10.37</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-12 07:00:00</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>no holiday</td>\n",
       "      <td>rain</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>12.73</td>\n",
       "      <td>261.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>8.35</td>\n",
       "      <td>1003.91</td>\n",
       "      <td>10.39</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-12 07:30:00</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>no holiday</td>\n",
       "      <td>rain</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>12.73</td>\n",
       "      <td>261.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>8.35</td>\n",
       "      <td>1003.91</td>\n",
       "      <td>10.39</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LCLid     holiday precipType                 icon  \\\n",
       "timestamp                                                                    \n",
       "2012-10-12 06:30:00  MAC000002  no holiday       rain  partly-cloudy-night   \n",
       "2012-10-12 07:00:00  MAC000002  no holiday       rain    partly-cloudy-day   \n",
       "2012-10-12 07:30:00  MAC000002  no holiday       rain    partly-cloudy-day   \n",
       "\n",
       "                           summary  visibility  windBearing  temperature  \\\n",
       "timestamp                                                                  \n",
       "2012-10-12 06:30:00  Mostly Cloudy       12.38        259.0        10.37   \n",
       "2012-10-12 07:00:00  Mostly Cloudy       12.73        261.0        10.39   \n",
       "2012-10-12 07:30:00  Mostly Cloudy       12.73        261.0        10.39   \n",
       "\n",
       "                     dewPoint  pressure  apparentTemperature  windSpeed  \\\n",
       "timestamp                                                                 \n",
       "2012-10-12 06:30:00      8.62   1002.72                10.37       6.11   \n",
       "2012-10-12 07:00:00      8.35   1003.91                10.39       6.71   \n",
       "2012-10-12 07:30:00      8.35   1003.91                10.39       6.71   \n",
       "\n",
       "                     humidity  month  weekday  \n",
       "timestamp                                      \n",
       "2012-10-12 06:30:00      0.89     10        4  \n",
       "2012-10-12 07:00:00      0.87     10        4  \n",
       "2012-10-12 07:30:00      0.87     10        4  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(Path(\"smartmeter\", \"resources\", \"preprocessed_labels.csv\"))\n",
    "label_df = label_df.set_index(\"timestamp\")\n",
    "label_df.index = pd.to_datetime(label_df.index)\n",
    "\n",
    "sample_df = pd.read_csv(Path(\"smartmeter\", \"resources\", \"preprocessed_samples.csv\"))\n",
    "sample_df = sample_df.set_index(\"timestamp\")\n",
    "sample_df.index = pd.to_datetime(sample_df.index)\n",
    "\n",
    "timeseries_df = pd.read_csv(Path(\"smartmeter\", \"resources\", \"timeseries.csv\"))\n",
    "timeseries_df = timeseries_df.set_index(\"timestamp\")\n",
    "timeseries_df.index = pd.to_datetime(timeseries_df.index)\n",
    "\n",
    "mimic_df = pd.read_csv(Path(\"mimic\", \"benchmark\", \"resources\", \"10011_episode1_timeseries.csv\"))\n",
    "mimic_target_df = pd.read_csv(Path(\"mimic\", \"benchmark\", \"resources\", \"10011_target.csv\"))\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a235af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-14 12:00:00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-14 18:00:00</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15 00:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15 06:00:00</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15 12:00:00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      y\n",
       "timestamp              \n",
       "2012-10-14 12:00:00   6\n",
       "2012-10-14 18:00:00  19\n",
       "2012-10-15 00:00:00   1\n",
       "2012-10-15 06:00:00  11\n",
       "2012-10-15 12:00:00   8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69191a6",
   "metadata": {},
   "source": [
    "## II. Split by Date\n",
    "\n",
    "In the case of the smartmeter dataset, we want to split the data into timespans. \n",
    "\n",
    "This can be done by either:\n",
    "* Specifying the date by which to split (special event which might induce concept drift)\n",
    "* Specifying span ratios\n",
    "\n",
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f55075",
   "metadata": {},
   "outputs": [],
   "source": [
    "bydate = [\"2013-03-03\"]\n",
    "# bydate = [\"2013-03-03\", \"2013-09-03\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1d3d8",
   "metadata": {},
   "source": [
    "The challenge in by date splits is that the windows have not yet been generated. Since there is only a single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2944763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_df\n",
    "y = label_df\n",
    "\n",
    "bydate = [parse(date) for date in bydate]\n",
    "\n",
    "label_splits = list()\n",
    "sample_splits = list()\n",
    "\n",
    "window_width = y.index[0] - X.index[0]\n",
    "forecast_horizon = y.index[-1] - X.index[-1]\n",
    "sample_width = window_width - forecast_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "420b6231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 06:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b95947",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in bydate:\n",
    "    label_split = y[y.index < date]\n",
    "    label_splits.append(label_split)\n",
    "    y = y[y.index >= date]\n",
    "    sample_splits.append(X[(X.index >= label_split.index[0] - window_width) & (X.index <= label_split.index[-1] - forecast_horizon)])\n",
    "    \n",
    "    \n",
    "label_splits.append(y)\n",
    "sample_splits.append(X[(X.index >= y.index[0] - window_width) & (X.index <= y.index[-1] - forecast_horizon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd7c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sample start: 2012-10-12 06:30:00, label start: 2012-10-14 12:00:00,  distance: 2 days 05:30:00 \n",
      " sample end: 2013-03-02 12:00:00,   label end: 2013-03-02 18:00:00,    distance: 0 days 06:00:00\n",
      " sample start: 2013-02-28 18:30:00, label start: 2013-03-03 00:00:00,  distance: 2 days 05:30:00 \n",
      " sample end: 2014-02-27 18:00:00,   label end: 2014-02-28 00:00:00,    distance: 0 days 06:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\" sample start: {sample.index[0]}, label start: {label.index[0]},  distance: {label.index[0] - sample.index[0]} \\n sample end: {sample.index[-1]},   label end: {label.index[-1]},    distance: {label.index[-1] - sample.index[-1]}\") for sample, label in zip(sample_splits, label_splits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e1923",
   "metadata": {},
   "source": [
    "## III. Split By Ratio\n",
    "\n",
    "The by ratio function is largely able to reuse the code provided by the by date function. After deducing the date on which to split, one simply needs to feed back the dates into the by date function.\n",
    "\n",
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c44e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a04c4",
   "metadata": {},
   "source": [
    "Lets compute the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e4bfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('501 days 12:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_span = label_df.index[-1] - label_df.index[0]\n",
    "total_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4492bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('300 days 21:36:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_span = total_span * (1 - (test_size + val_size))\n",
    "train_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92decd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013-08-11 09:36:00', '2013-11-19 16:48:00']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date = list()\n",
    "split_date.append(str(label_df.index[0] + train_span))\n",
    "\n",
    "if val_size:\n",
    "    split_date.append(str(label_df.index[0] + train_span + val_size*total_span))\n",
    "split_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ef08d",
   "metadata": {},
   "source": [
    "# IV. Integration\n",
    "Now, that we finished with the proof of concept, we can continue by intergrating and testing the new functionalites with the already existing module.\n",
    "\n",
    "## By Date Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee8f8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.2814995655232342,test: 0.3654570281789217val: 0.35304340629784414\n",
      "\n",
      "train: 0.27873704982733105,test: 0.36655155402072026val: 0.3547113961519487\n"
     ]
    }
   ],
   "source": [
    "bydate = [\"2013-03-03\", \"2013-09-03\"]\n",
    "\n",
    "def make_date_split(X, dates):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if isinstance(dates, str):\n",
    "        dates = [dates]\n",
    "\n",
    "    dates = [parse(date) for date in dates] + [X.index[-1]]\n",
    "\n",
    "    sample_splits = list()\n",
    "    \n",
    "    for date in dates:\n",
    "        sample_split = X[X.index < date]\n",
    "        sample_splits.append(sample_split)\n",
    "        X = X[X.index >= date]\n",
    "        \n",
    "    return tuple(sample_splits)\n",
    "\n",
    "# print(len(make_date_split(sample_df, bydate)))\n",
    "X, X1, X2 = make_date_split(sample_df, bydate)\n",
    "print(f\"train: {len(X) / (len(X) + len(X1) + len(X2))},\"\n",
    "      f\"test: {len(X1) / (len(X) + len(X1) + len(X2))}\"\n",
    "      f\"val: {len(X2) / (len(X) + len(X1) + len(X2))}\\n\")\n",
    "\n",
    "def make_date_split(X, y, dates):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if isinstance(dates, str):\n",
    "        dates = [dates]\n",
    "\n",
    "    dates = [parse(date) for date in dates] + [y.index[-1]]\n",
    "\n",
    "    label_splits = list()\n",
    "    sample_splits = list()\n",
    "\n",
    "    window_width = y.index[0] - X.index[0]\n",
    "    forecast_horizon = y.index[-1] - X.index[-1]\n",
    "    sample_width = window_width - forecast_horizon\n",
    "    \n",
    "    for date in dates:\n",
    "        label_split = y[y.index < date]\n",
    "        label_splits.append(label_split)\n",
    "        y = y[y.index >= date]\n",
    "        sample_split = X[(X.index >= label_split.index[0] - window_width) & (X.index <= label_split.index[-1] - forecast_horizon)]\n",
    "        sample_splits.append(sample_split)\n",
    "        \n",
    "    return (*sample_splits, *label_splits)\n",
    "\n",
    "X, X1, X2, y, y1, y2 = make_date_split(sample_df, label_df, bydate)\n",
    "# print(len(make_date_split(sample_df, label_df, bydate)))\n",
    "print(f\"train: {len(X) / (len(X) + len(X1) + len(X2))},\"\n",
    "      f\"test: {len(X1) / (len(X) + len(X1) + len(X2))}\"\n",
    "      f\"val: {len(X2) / (len(X) + len(X1) + len(X2))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633eb4ef",
   "metadata": {},
   "source": [
    "## By Time Ratio Split Function\n",
    "\n",
    "The by ratio function is then again based on the make_data_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62d72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_timeratio_split(X, y, test_size=0.5, val_size=0.):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    total_span = label_df.index[-1] - label_df.index[0]\n",
    "    train_span = total_span * (1 - (test_size + val_size))\n",
    "\n",
    "    dates = list()\n",
    "    dates.append(str(label_df.index[0] + train_span))\n",
    "\n",
    "    if val_size:\n",
    "        dates.append(str(label_df.index[0] + train_span + val_size*total_span))\n",
    "    \n",
    "    return make_date_split(X, y, dates)\n",
    "\n",
    "len(make_timeratio_split(sample_df, label_df, test_size=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c235984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1113573407202216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, X2, y1, y2 = make_timeratio_split(sample_df, label_df, test_size=0.9)\n",
    "len(y1)/len(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8815b2",
   "metadata": {},
   "source": [
    "# V. Class implementation\n",
    "\n",
    "We integrate the functions and leagacy code with now implemented functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de7fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from multipledispatch) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install multipledispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e76fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multipledispatch import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4bc5f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitUtility():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\" \n",
    "        self.X_out = {\n",
    "            \"train\": None,\n",
    "            \"test\": None,\n",
    "            \"val\": None\n",
    "        }\n",
    "        \n",
    "        self.y_out = {\n",
    "            \"train\": None,\n",
    "            \"test\": None,\n",
    "            \"val\": None\n",
    "        }\n",
    "        \n",
    "        self.X_buffer = {\n",
    "            \"train\": list(),\n",
    "            \"test\": list(),\n",
    "            \"val\": list()\n",
    "        }\n",
    "        \n",
    "        self.y_buffer = {\n",
    "            \"train\": list(),\n",
    "            \"test\": list(),\n",
    "            \"val\": list()\n",
    "        }\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def train_test_split(self, X, y=None, test_size=0.5, val_size=0., dates=[], method=\"sample\", concatenate=True):\n",
    "        \"\"\"\n",
    "        This function splits the provided data into a test and train data set.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_size = float(test_size)\n",
    "        val_size = float(val_size)\n",
    "        \n",
    "        if dates:\n",
    "            method = \"date\"\n",
    "            \n",
    "            if isinstance(dates, str):\n",
    "                dates = [dates]\n",
    "                \n",
    "        print(method)\n",
    "            \n",
    "        method_switch = {\n",
    "            \"date\": self.make_date_split,\n",
    "            \"time\": self.make_timeratio_split,\n",
    "            \"sample\": self.make_frame_split\n",
    "        }\n",
    "        \n",
    "        args_switch = {\n",
    "            \"date\": {\"dates\": dates},\n",
    "            \"time\": {\"test_size\": test_size, \n",
    "                     \"val_size\": val_size,\n",
    "                    },\n",
    "            \"sample\": {\"test_size\": test_size, \"val_size\": val_size}\n",
    "        }\n",
    "                \n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, np.ndarray) and dates:   \n",
    "            if y is not None: \n",
    "                method_switch[method](X, y, **args_switch[method])\n",
    "            else:\n",
    "                method_switch[method](X, **args_switch[method])\n",
    "\n",
    "        elif isinstance(X, dict) and len(X) == 1:\n",
    "            if y is not None: y = [*y.values()][0]\n",
    "            return self.make_frame_split([*X.values()][0], y, test_size=test_size, val_size=val_size)\n",
    "        \n",
    "        elif isinstance(X, dict) and method in [\"time\", \"date\"]:\n",
    "            if not y:\n",
    "                y = {}\n",
    "            self.make_perdictionary_split(X, y, *args_switch[method].values(), splitter=method_switch[method])\n",
    "        \n",
    "        elif isinstance(X, dict):\n",
    "            if not y:\n",
    "                y = {}\n",
    "            self.make_dictionary_split(X, y, test_size, val_size)\n",
    "\n",
    "        return tuple(self.make_returns())\n",
    "    \n",
    "    @dispatch(pd.DataFrame, list) \n",
    "    def make_date_split(self, X, dates):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if isinstance(dates, str):\n",
    "            dates = [dates]\n",
    "\n",
    "        dates = [parse(date) for date in dates] + [X.index[-1]]\n",
    "        sample_splits = list()\n",
    "\n",
    "        for name, date in zip(self.X_out.keys(), dates):\n",
    "            self.X_out[name] = X[X.index < date]\n",
    "            X = X[X.index >= date]\n",
    "            if not len(X): break\n",
    "                \n",
    "        return\n",
    "\n",
    "    @dispatch(pd.DataFrame, pd.DataFrame, list) \n",
    "    def make_date_split(self, X, y, dates):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if isinstance(dates, str):\n",
    "            dates = [dates]\n",
    "\n",
    "        dates = [parse(date) for date in dates] + [y.index[-1]]\n",
    "\n",
    "        window_width = y.index[0] - X.index[0]\n",
    "        forecast_horizon = y.index[-1] - X.index[-1]\n",
    "        sample_width = window_width - forecast_horizon\n",
    "        \n",
    "        for name, date in zip(self.y_out.keys(), dates):\n",
    "            label_split = y[y.index < date]\n",
    "            self.y_out[name] = label_split\n",
    "            y = y[y.index >= date]\n",
    "            self.X_out[name] = X[(X.index >= label_split.index[0] - window_width) & (X.index <= label_split.index[-1] - forecast_horizon)]\n",
    "            if not len(y): break\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def make_timeratio_split(self, X, y={}, test_size=0., val_size=0.):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        total_span = X.index[-1] - X.index[0]\n",
    "        train_span = total_span * (1 - (test_size + val_size))\n",
    "        dates = list()\n",
    "        dates.append(str(X.index[0] + train_span))\n",
    "\n",
    "        if val_size:\n",
    "            dates.append(str(X.index[0] + train_span + val_size*total_span))\n",
    "        \n",
    "        if len(y):\n",
    "            self.make_date_split(X, y, dates)\n",
    "        else:\n",
    "            self.make_date_split(X, dates)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    @dispatch(pd.DataFrame)\n",
    "    def make_frame_split(self, X, test_size, val_size):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        total_size = test_size + val_size\n",
    "        self.X_out[\"train\"], self.X_out[\"test\"] = model_selection.train_test_split(X, test_size=total_size, shuffle=False)\n",
    "        \n",
    "        if val_size:\n",
    "            val_test_ratio =  val_size / total_size\n",
    "            \n",
    "            self.X_out[\"test\"], self.X_out[\"val\"] = model_selection.train_test_split(self.X_out[\"test\"], test_size=val_test_ratio, shuffle=False)\n",
    "    \n",
    "        return\n",
    "    \n",
    "    @dispatch(pd.DataFrame, pd.DataFrame)\n",
    "    def make_frame_split(self, X, y, test_size, val_size):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        total_size = test_size + val_size\n",
    "        (self.X_out[\"train\"], \n",
    "         self.X_out[\"test\"], \n",
    "         self.y_out[\"train\"], \n",
    "         self.y_out[\"test\"]) = model_selection.train_test_split(X, y, test_size=total_size, shuffle=False)\n",
    "        \n",
    "        if val_size:\n",
    "            val_test_ratio = val_size / total_size\n",
    "            \n",
    "            (self.X_out[\"test\"], \n",
    "             self.X_out[\"val\"], \n",
    "             self.y_out[\"test\"], \n",
    "             self.y_out[\"val\"]) = model_selection.train_test_split(self.X_out[\"test\"], self.y_out[\"test\"], test_size=val_test_ratio, shuffle=False)          \n",
    "        \n",
    "        return\n",
    "    @dispatch(dict, dict, float, float)\n",
    "    def make_perdictionary_split(self, X_dict, y_dict, test_size, val_size, splitter=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        column_length = (int(test_size!=0) + int(val_size!=0) + 1) * (1 + int(y_dic!=None))\n",
    "        \n",
    "        for i, (key, X) in enumerate(X_dict.items()):\n",
    "            if len(y_dict):\n",
    "                splitter(X, y_dict[key], test_size=test_size, val_size=val_size)\n",
    "            else:\n",
    "                splitter(X, test_size=test_size, val_size=val_size)\n",
    "            self.buffer()\n",
    "            \n",
    "        self.save()\n",
    "    \n",
    "    @dispatch(dict, dict, list)\n",
    "    def make_perdictionary_split(self, X_dict, y_dict, dates, splitter=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        column_length = len(dates) + 1\n",
    "        \n",
    "        for i, (key, X) in enumerate(X_dict.items()):\n",
    "            if len(y_dict):\n",
    "                splitter(X, y_dict[key], dates)\n",
    "            else:\n",
    "                splitter(X, dates)\n",
    "            self.buffer()\n",
    "            \n",
    "        self.save()\n",
    "            \n",
    "    def make_dictionary_split(self, X_dict, y_dict, test_size=0.5, val_size=None, concatenate=True):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        test_subjects, test_size_real = self.make_subject_ratio(X_dict, test_size)\n",
    "\n",
    "        if test_size > 0 and not len(test_subjects):\n",
    "            raise(\"Test set empty!\")\n",
    "\n",
    "        train_subjects = set(X_dict.keys()) - set(test_subjects)\n",
    "\n",
    "        if val_size:\n",
    "            X_train_dict = {key: X_dict[key] for key in train_subjects}\n",
    "            train_size = (1 - test_size)\n",
    "            val_train_ratio = val_size/train_size\n",
    "            val_subjects, val_size_real = self.make_subject_ratio(X_train_dict, val_train_ratio)\n",
    "\n",
    "            if val_size > 0 and not len(val_subjects):\n",
    "                raise(\"Test set empty!\")\n",
    "\n",
    "            train_subjects = train_subjects - set(val_subjects)\n",
    "            self.X_out[\"val\"] = [X_dict[subject] for subject in val_subjects]\n",
    "\n",
    "        self.X_out[\"train\"] = [X_dict[subject] for subject in list(train_subjects)]\n",
    "        self.X_out[\"test\"] = [X_dict[subject] for subject in test_subjects]\n",
    "        \n",
    "        if len(y_dict):\n",
    "            self.y_out[\"train\"] = [y_dict[subject] for subject in list(train_subjects)]\n",
    "            self.y_out[\"test\"] = [y_dict[subject] for subject in test_subjects]\n",
    "            \n",
    "            if val_size:\n",
    "                self.y_out[\"val\"] = [y_dict[subject] for subject in val_subjects] \n",
    "\n",
    "        return\n",
    "    \n",
    "    def buffer(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for key, value in self.X_out.items():\n",
    "            self.X_buffer[key].append(self.X_out[key])\n",
    "        for key, value in self.y_out.items():\n",
    "            self.y_buffer[key].append(self.y_out[key])\n",
    "                        \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for key in self.X_out.keys():\n",
    "            if self.X_buffer[key][0] is not None:\n",
    "                self.X_out[key] = self.X_buffer[key]\n",
    "            else:\n",
    "                self.X_out[key] = None\n",
    "                \n",
    "            if self.y_buffer[key][0] is not None:\n",
    "                self.y_out[key] = self.y_buffer[key]\n",
    "            else:\n",
    "                self.y_out[key] = None\n",
    "                            \n",
    "    def make_returns(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for key in self.X_out.keys():\n",
    "            if not isinstance(self.X_out[key], list) and self.X_out[key] is not None:\n",
    "                self.X_out[key] = [self.X_out[key]]\n",
    "                self.y_out[key] = [self.y_out[key]]\n",
    "                \n",
    "        rets = (*[value for value in self.X_out.values() if value is not None], \n",
    "                *[value for value in self.y_out.values() if value is not None])\n",
    "\n",
    "        for key in self.X_out.keys():\n",
    "            self.X_out[key] = None\n",
    "            self.y_out[key] = None\n",
    "            \n",
    "        for key in self.X_buffer.keys():\n",
    "            self.X_buffer[key] = list()\n",
    "            self.y_buffer[key] = list()\n",
    "        \n",
    "        \n",
    "        return rets\n",
    "        \n",
    "    def make_subject_ratio(self, X_dict, target_size):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        total_samples = get_sample_size(X_dict)\n",
    "\n",
    "        # Create a dataframe containing the participant id and share on total sample as ratio\n",
    "        subject_ratios_pairs = [(subject, len(X_dict[subject])/total_samples) for subject in X_dict.keys()]\n",
    "\n",
    "        # Build dataframe\n",
    "        ratio_df = pd.DataFrame(subject_ratios_pairs, \n",
    "                                columns=['participant', 'ratio'])\n",
    "\n",
    "        ratio_df = ratio_df.sort_values('ratio')\n",
    "        ratio_df = ratio_df.set_index('participant')\n",
    "\n",
    "        subjects = list()\n",
    "\n",
    "        best_diff = 1e18\n",
    "        tolerance = 0.005\n",
    "        max_iter = 1000\n",
    "        iter = 0\n",
    "\n",
    "        while best_diff > tolerance and iter < max_iter:\n",
    "\n",
    "            current_size = 0\n",
    "            remaining_pairs_df = ratio_df.sample(frac=1)\n",
    "\n",
    "            while current_size < target_size:\n",
    "                current_to_rarget_diff = target_size - current_size\n",
    "                remaining_pairs_df = remaining_pairs_df[remaining_pairs_df['ratio'] < current_to_rarget_diff]\n",
    "\n",
    "                if not len(remaining_pairs_df): break\n",
    "\n",
    "                next_subject = remaining_pairs_df.iloc[-1]\n",
    "\n",
    "                current_size += next_subject['ratio']\n",
    "                subject_name = next_subject.name\n",
    "                subjects.append(subject_name)\n",
    "                remaining_pairs_df = remaining_pairs_df.drop(subject_name)\n",
    "\n",
    "            diff = abs(target_size - current_size)\n",
    "\n",
    "            if diff < best_diff:\n",
    "                best_subjects = subjects\n",
    "                best_size = current_size\n",
    "                best_diff = diff\n",
    "\n",
    "            iter += 1\n",
    "\n",
    "        return best_subjects, best_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f09667",
   "metadata": {},
   "source": [
    "## VI. Tetsting\n",
    "\n",
    "Before refactoring the functionality in the codebase, we want to make sure, that the functionality performs well.\n",
    "\n",
    "### Dictionaries\n",
    "\n",
    "We want dictionaries of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dacf833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.smartmeter import Preprocessor\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "X_dic = {}\n",
    "y_dic = {}\n",
    "\n",
    "n_samples = len(timeseries_df)\n",
    "\n",
    "for index in range(20):\n",
    "    i = index + 1\n",
    "    X_household, y_household = preprocessor.transform(timeseries_df=timeseries_df.iloc[:int((n_samples/i) - 1), :],\n",
    "                                                      forecast_horizon=\"qdaily\",\n",
    "                                                      input_width=48)\n",
    "    X_household_new = {}\n",
    "    y_household_new = {}\n",
    "    \n",
    "    for key, values in X_household.items():\n",
    "        X_household_new[f\"{key}_{1}\"] = values\n",
    "        \n",
    "    for key, values in y_household.items():\n",
    "        y_household_new[f\"{key}_{1}\"] = values\n",
    "        \n",
    "    X_dic.update(X_household_new)\n",
    "    y_dic.update(y_household_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "280a480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "su = SplitUtility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54145807",
   "metadata": {},
   "source": [
    "### Split By Time Ratio\n",
    "\n",
    "**With targets & val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e3b46f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.601593625498008"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2, y, y1, y2 = su.train_test_split(X_dic, y_dic, test_size=0.2, val_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]) + len(X2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776a45c",
   "metadata": {},
   "source": [
    "**With val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fa78990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.603585657370518"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2 = su.train_test_split(X_dic, test_size=0.2, val_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]) + len(X2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199b36d",
   "metadata": {},
   "source": [
    "**With target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "100a38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8007968127490039"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, y, y1 = su.train_test_split(X_dic, y_dic, test_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84778592",
   "metadata": {},
   "source": [
    "**Blank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e29bb6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8027888446215139"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1 = su.train_test_split(X_dic, test_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268601c3",
   "metadata": {},
   "source": [
    "### Split By Households/Subjects\n",
    "\n",
    "**With targets & val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fcd99b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6055940233236151"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2, y, y1, y2 = su.train_test_split(X_dic, y_dic, test_size=0.2, val_size=0.2)\n",
    "get_sample_size(X) / (get_sample_size(X) + get_sample_size(X1) + get_sample_size(X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90daba3",
   "metadata": {},
   "source": [
    "**Val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f29bf700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.603585657370518"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2 = su.train_test_split(X_dic, test_size=0.2, val_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]) + len(X2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d9dea",
   "metadata": {},
   "source": [
    "**Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a9f2ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8007968127490039"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, y, y1 = su.train_test_split(X_dic, y_dic, test_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096a53b",
   "metadata": {},
   "source": [
    "**Blank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "badcc80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8027888446215139"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1 = su.train_test_split(X_dic, test_size=0.2, method=\"time\")\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b43ea",
   "metadata": {},
   "source": [
    "### Split by Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "26428e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bydate = [\"2013-03-03\", \"2013-09-03\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31383b",
   "metadata": {},
   "source": [
    "**With targets & val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "80dc74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32415340677274584"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2, y, y1, y2 = su.train_test_split(X_dic, y_dic, dates=bydate)\n",
    "get_sample_size(X) / (get_sample_size(X) + get_sample_size(X1) + get_sample_size(X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01492d6",
   "metadata": {},
   "source": [
    "**Val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a1316059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28087649402390436"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2 = su.train_test_split(X_dic, dates=bydate)\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]) + len(X2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a47a36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bydate = [\"2013-03-03\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a6e3",
   "metadata": {},
   "source": [
    "**Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc919b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2788844621513944"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, y, y1 = su.train_test_split(X_dic, y_dic, dates=bydate)\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f085a7",
   "metadata": {},
   "source": [
    "**Blank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b9a9944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28087649402390436"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1 = su.train_test_split(X_dic, dates=bydate)\n",
    "len(X[0]) / (len(X[0]) + len(X1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91792c0d",
   "metadata": {},
   "source": [
    "### Split by Samples\n",
    "\n",
    "**Where do I need this then**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c2564302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7980295566502463"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1 = su.train_test_split(mimic_df, test_size=0.2)\n",
    "len(X) / (len(X) + len(X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932686d",
   "metadata": {},
   "source": [
    "**Val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a95afc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5960591133004927"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1, X2 = su.train_test_split(mimic_df, test_size=0.2, val_size=0.2)\n",
    "len(X) / (len(X) + len(X1) + len(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b9f54a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980295566502463"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1 = su.train_test_split(mimic_df, test_size=0.2)\n",
    "len(X) / (len(X) + len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5c845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
