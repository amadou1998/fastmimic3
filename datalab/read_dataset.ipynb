{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from preprocessing.scalers import MinMaxScaler\n",
    "os.getcwd()\n",
    "wd = os.getenv(\"WORKINGDIR\")\n",
    "TEST_DATA_DIR = Path(wd, \"tests\", \"data\", \"physionet.org\", \"files\", \"mimiciii-demo\", \"1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    -\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 313  - ---------- Iterative Dataset Extraction: ALL -----------------------\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 314  - Starting iterative data extraction.\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 315  - Extracting data from source:\n",
      "                                    - /home/amadou/CodeWorkspace/fastmimic3/tests/data/physionet.org/files/mimiciii-demo/1.4\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 316  - Saving data at location:\n",
      "                                    - tmp/extracted\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 329  - Extracting ICU history data ... --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 342  - Done extracting ICU history data\n",
      "INFO --- 06-19 22:07:53 : datasets/extraction/__init__.py  : L 352  - Extracting Patient diagnosis data ... --- 06-19 22:07:54 : datasets/extraction/__init__.py  : L 361  - Done extracting Patient diagnosis data\n",
      "INFO --- 06-19 22:07:54 : datasets/extraction/__init__.py  : L 388  - Extracting subject events ...\n",
      "INFO --- 06-19 22:07:54 : datasets/readers.py  : L 1211 - Starting reader initialization.\n",
      "INFO --- 06-19 22:07:54 : datasets/extraction/progress_publisher.py  : L 119  -INFO --- 06-19 22:07:54 : datasets/readers.py  : L 1225 - Initializing reader and starting at row:\n",
      "                                    - CHARTEVENTS.csv: 0 - LABEVENTS.csv: 0 - OUTPUTEVENTS.csv: 0\n",
      " Processed event rows: \n",
      "                                    - CHARTEVENTS:       0/758355\n",
      "                                    - LABEVENTS:      0/76074\n",
      "                                    - OUTPUTEVENTS:      0/11320\n",
      "INFO --- 06-19 22:07:57 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:   75835/758355\n",
      "                                    - LABEVENTS:  75835/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:07:57 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  151670/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:07:58 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  227505/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:07:59 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  303340/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:07:59 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  379175/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:00L 143  : datasets/extraction/progress_publisher.py  :  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  455010/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:01 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  530845/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:02 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  606680/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:02 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  682515/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:02 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  682520/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  682520/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:03 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:04 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:04 : datasets/extraction/progress_publisher.py  : L 143  - Processed event rows: \n",
      "                                    - CHARTEVENTS:  758355/758355\n",
      "                                    - LABEVENTS:  76074/76074\n",
      "                                    - OUTPUTEVENTS:  11320/11320\n",
      "INFO --- 06-19 22:08:04 : datasets/extraction/__init__.py  : L 404  - Extraction timeseries data from subject events\n",
      "INFO --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 1 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 2 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 3 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 4 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 5 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 6 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 7 --- 06-19 22:08:09 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 8 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 9 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 10 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 11 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 12 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 13 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 14 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 15 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 16 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 17 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 18 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 19 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 20 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 21 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 22 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 23 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 24 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 25 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 26 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 27 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 28 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 29 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 30 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 31 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 32 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 33 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 34 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 35 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 36 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 37 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 38 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 39 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 40 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 41 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 42 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 43 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 44 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 45 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 46 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 47 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 48 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 49 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 50 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 51 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 52 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 53 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 54 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 55 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 56 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 57 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 58 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 59 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 60 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 61 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 62 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 63 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 64 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 65 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 66 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 67 --- 06-19 22:08:10 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 68 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 69 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 70 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 71 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 72 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 73 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 74 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 75 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 76 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 77 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 78 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 79 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 80 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 81 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 82 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 83 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 84 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 85 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 86 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 87 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 88 --- 06-19 22:08:11 : datasets/extraction/timeseries_processor.py  : L 205  - Subject directories extracted: 89 --- 06-19 22:08:11 : datasets/extraction/__init__.py  : L 418  - Subject directories extracted: 89\n",
      "                                    -\n",
      "INFO --- 06-19 22:08:12 : datasets/processors/__init__.py  : L 355  - ---------- Iterative preprocessing: DECOMP -------------------------\n",
      "INFO --- 06-19 22:08:12 : datasets/processors/__init__.py  : L 356  - Preprocessing data for task DECOMP.\n",
      "INFO --- 06-19 22:08:12 : datasets/processors/__init__.py  : L 404  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 0\n",
      "                                    - Preprocessed stays: 0\n",
      "                                    - Preprocessed samples: 0\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 1\n",
      "                                    - Preprocessed stays: 1\n",
      "                                    - Preprocessed samples: 13\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 2\n",
      "                                    - Preprocessed stays: 2\n",
      "                                    - Preprocessed samples: 57\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 3\n",
      "                                    - Preprocessed stays: 3\n",
      "                                    - Preprocessed samples: 73\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 4\n",
      "                                    - Preprocessed stays: 4\n",
      "                                    - Preprocessed samples: 108\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 5\n",
      "                                    - Preprocessed stays: 5\n",
      "                                    - Preprocessed samples: 274\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 6\n",
      "                                    - Preprocessed stays: 6\n",
      "                                    - Preprocessed samples: 602\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 7\n",
      "                                    - Preprocessed stays: 7\n",
      "                                    - Preprocessed samples: 661\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:16 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 8\n",
      "                                    - Preprocessed stays: 8\n",
      "                                    - Preprocessed samples: 708\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 9\n",
      "                                    - Preprocessed stays: 9\n",
      "                                    - Preprocessed samples: 719\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 10\n",
      "                                    - Preprocessed stays: 10\n",
      "                                    - Preprocessed samples: 734\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 11\n",
      "                                    - Preprocessed stays: 11\n",
      "                                    - Preprocessed samples: 787\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 12\n",
      "                                    - Preprocessed stays: 12\n",
      "                                    - Preprocessed samples: 957\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 13\n",
      "                                    - Preprocessed stays: 13\n",
      "                                    - Preprocessed samples: 1007\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 14\n",
      "                                    - Preprocessed stays: 14\n",
      "                                    - Preprocessed samples: 1092\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 15\n",
      "                                    - Preprocessed stays: 15\n",
      "                                    - Preprocessed samples: 1109\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 16\n",
      "                                    - Preprocessed stays: 16\n",
      "                                    - Preprocessed samples: 1130\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:17 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 17\n",
      "                                    - Preprocessed stays: 17\n",
      "                                    - Preprocessed samples: 1172\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 18\n",
      "                                    - Preprocessed stays: 20\n",
      "                                    - Preprocessed samples: 1342\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 19\n",
      "                                    - Preprocessed stays: 21\n",
      "                                    - Preprocessed samples: 1395\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 20\n",
      "                                    - Preprocessed stays: 22\n",
      "                                    - Preprocessed samples: 1424\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 21\n",
      "                                    - Preprocessed stays: 23\n",
      "                                    - Preprocessed samples: 1460\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 22\n",
      "                                    - Preprocessed stays: 24\n",
      "                                    - Preprocessed samples: 1479\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 23\n",
      "                                    - Preprocessed stays: 25\n",
      "                                    - Preprocessed samples: 1499\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 24\n",
      "                                    - Preprocessed stays: 26\n",
      "                                    - Preprocessed samples: 1576\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 25\n",
      "                                    - Preprocessed stays: 27\n",
      "                                    - Preprocessed samples: 1623\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 26\n",
      "                                    - Preprocessed stays: 28\n",
      "                                    - Preprocessed samples: 2218\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 27\n",
      "                                    - Preprocessed stays: 29\n",
      "                                    - Preprocessed samples: 2259\n",
      "                                    - Skipped subjects: 1\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 28\n",
      "                                    - Preprocessed stays: 30\n",
      "                                    - Preprocessed samples: 2377\n",
      "                                    - Skipped subjects: 1\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 29\n",
      "                                    - Preprocessed stays: 31\n",
      "                                    - Preprocessed samples: 2733\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 30\n",
      "                                    - Preprocessed stays: 32\n",
      "                                    - Preprocessed samples: 2759\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 31\n",
      "                                    - Preprocessed stays: 33\n",
      "                                    - Preprocessed samples: 2770\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 32\n",
      "                                    - Preprocessed stays: 34\n",
      "                                    - Preprocessed samples: 2961\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 33\n",
      "                                    - Preprocessed stays: 35\n",
      "                                    - Preprocessed samples: 3005\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 34\n",
      "                                    - Preprocessed stays: 36\n",
      "                                    - Preprocessed samples: 3111\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 35\n",
      "                                    - Preprocessed stays: 37\n",
      "                                    - Preprocessed samples: 3176\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 36\n",
      "                                    - Preprocessed stays: 38\n",
      "                                    - Preprocessed samples: 3195\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 37\n",
      "                                    - Preprocessed stays: 40\n",
      "                                    - Preprocessed samples: 3477\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 38\n",
      "                                    - Preprocessed stays: 41\n",
      "                                    - Preprocessed samples: 3498\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:18 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 39\n",
      "                                    - Preprocessed stays: 43\n",
      "                                    - Preprocessed samples: 3700\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 40\n",
      "                                    - Preprocessed stays: 44\n",
      "                                    - Preprocessed samples: 4014\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 41\n",
      "                                    - Preprocessed stays: 45\n",
      "                                    - Preprocessed samples: 4161\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 42\n",
      "                                    - Preprocessed stays: 46\n",
      "                                    - Preprocessed samples: 4198\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 43\n",
      "                                    - Preprocessed stays: 47\n",
      "                                    - Preprocessed samples: 4217\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 44\n",
      "                                    - Preprocessed stays: 50\n",
      "                                    - Preprocessed samples: 4379\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 45\n",
      "                                    - Preprocessed stays: 51\n",
      "                                    - Preprocessed samples: 4430\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 46\n",
      "                                    - Preprocessed stays: 52\n",
      "                                    - Preprocessed samples: 4453\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 47\n",
      "                                    - Preprocessed stays: 54\n",
      "                                    - Preprocessed samples: 4479\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 48\n",
      "                                    - Preprocessed stays: 55\n",
      "                                    - Preprocessed samples: 4488\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 49\n",
      "                                    - Preprocessed stays: 56\n",
      "                                    - Preprocessed samples: 4530\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 50\n",
      "                                    - Preprocessed stays: 57\n",
      "                                    - Preprocessed samples: 5228\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 51\n",
      "                                    - Preprocessed stays: 58\n",
      "                                    - Preprocessed samples: 5360\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:19 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 52\n",
      "                                    - Preprocessed stays: 59\n",
      "                                    - Preprocessed samples: 5621\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 53\n",
      "                                    - Preprocessed stays: 60\n",
      "                                    - Preprocessed samples: 5730\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 54\n",
      "                                    - Preprocessed stays: 61\n",
      "                                    - Preprocessed samples: 5768\n",
      "                                    - Skipped subjects: 2\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 55\n",
      "                                    - Preprocessed stays: 63\n",
      "                                    - Preprocessed samples: 5836\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 56\n",
      "                                    - Preprocessed stays: 64\n",
      "                                    - Preprocessed samples: 5850\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 57\n",
      "                                    - Preprocessed stays: 66\n",
      "                                    - Preprocessed samples: 6035\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 58\n",
      "                                    - Preprocessed stays: 67\n",
      "                                    - Preprocessed samples: 6047\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 59\n",
      "                                    - Preprocessed stays: 68\n",
      "                                    - Preprocessed samples: 6065\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 60\n",
      "                                    - Preprocessed stays: 69\n",
      "                                    - Preprocessed samples: 6115\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 61\n",
      "                                    - Preprocessed stays: 70\n",
      "                                    - Preprocessed samples: 6279\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 62\n",
      "                                    - Preprocessed stays: 71\n",
      "                                    - Preprocessed samples: 6290\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 63\n",
      "                                    - Preprocessed stays: 72\n",
      "                                    - Preprocessed samples: 6345\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 64\n",
      "                                    - Preprocessed stays: 73\n",
      "                                    - Preprocessed samples: 6426\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 65\n",
      "                                    - Preprocessed stays: 74\n",
      "                                    - Preprocessed samples: 6463\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 66\n",
      "                                    - Preprocessed stays: 75\n",
      "                                    - Preprocessed samples: 7205\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 67\n",
      "                                    - Preprocessed stays: 76\n",
      "                                    - Preprocessed samples: 7512\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 68\n",
      "                                    - Preprocessed stays: 78\n",
      "                                    - Preprocessed samples: 7652\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 69\n",
      "                                    - Preprocessed stays: 79\n",
      "                                    - Preprocessed samples: 7679\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 70\n",
      "                                    - Preprocessed stays: 80\n",
      "                                    - Preprocessed samples: 7743\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 71\n",
      "                                    - Preprocessed stays: 82\n",
      "                                    - Preprocessed samples: 7969\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 72\n",
      "                                    - Preprocessed stays: 83\n",
      "                                    - Preprocessed samples: 8032\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 73\n",
      "                                    - Preprocessed stays: 84\n",
      "                                    - Preprocessed samples: 8863\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 74\n",
      "                                    - Preprocessed stays: 85\n",
      "                                    - Preprocessed samples: 8898\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 75\n",
      "                                    - Preprocessed stays: 86\n",
      "                                    - Preprocessed samples: 9108\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 76\n",
      "                                    - Preprocessed stays: 87\n",
      "                                    - Preprocessed samples: 9123\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 77\n",
      "                                    - Preprocessed stays: 89\n",
      "                                    - Preprocessed samples: 9658\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 78\n",
      "                                    - Preprocessed stays: 90\n",
      "                                    - Preprocessed samples: 9685\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 79\n",
      "                                    - Preprocessed stays: 91\n",
      "                                    - Preprocessed samples: 9791\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 80\n",
      "                                    - Preprocessed stays: 92\n",
      "                                    - Preprocessed samples: 9804\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 81\n",
      "                                    - Preprocessed stays: 93\n",
      "                                    - Preprocessed samples: 9930\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 82\n",
      "                                    - Preprocessed stays: 94\n",
      "                                    - Preprocessed samples: 9950\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 83\n",
      "                                    - Preprocessed stays: 95\n",
      "                                    - Preprocessed samples: 9986\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 84\n",
      "                                    - Preprocessed stays: 96\n",
      "                                    - Preprocessed samples: 9994\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 85\n",
      "                                    - Preprocessed stays: 97\n",
      "                                    - Preprocessed samples: 10017\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 443  - Preprocessing timeseries data:\n",
      "                                    - Preprocessed subjects: 86\n",
      "                                    - Preprocessed stays: 111\n",
      "                                    - Preprocessed samples: 10863\n",
      "                                    - Skipped subjects: 3\n",
      "INFO --- 06-19 22:08:20 : datasets/processors/__init__.py  : L 453  - Finalized for task DECOMP in directory:\n",
      "                                    - tmp/processed/DECOMP\n",
      "                                    -\n",
      "INFO --- 06-19 22:08:21 : datasets/processors/__init__.py  : L 355  - ---------- Iterative discretizing: DECOMP --------------------------\n",
      "INFO --- 06-19 22:08:21 : datasets/processors/__init__.py  : L 356  - Discretizing data for task DECOMP.\n",
      "INFO --- 06-19 22:08:21 : datasets/processors/__init__.py  : L 404  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 0\n",
      "                                    - Discretized stays: 0\n",
      "                                    - Discretized samples: 0\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 1\n",
      "                                    - Discretized stays: 1\n",
      "                                    - Discretized samples: 13\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 2\n",
      "                                    - Discretized stays: 2\n",
      "                                    - Discretized samples: 57\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 3\n",
      "                                    - Discretized stays: 3\n",
      "                                    - Discretized samples: 73\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 4\n",
      "                                    - Discretized stays: 4\n",
      "                                    - Discretized samples: 108\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 5\n",
      "                                    - Discretized stays: 5\n",
      "                                    - Discretized samples: 274\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 6\n",
      "                                    - Discretized stays: 6\n",
      "                                    - Discretized samples: 602\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:39 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 7\n",
      "                                    - Discretized stays: 7\n",
      "                                    - Discretized samples: 661\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 8\n",
      "                                    - Discretized stays: 8\n",
      "                                    - Discretized samples: 708\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 9\n",
      "                                    - Discretized stays: 9\n",
      "                                    - Discretized samples: 719\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 10\n",
      "                                    - Discretized stays: 10\n",
      "                                    - Discretized samples: 734\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 11\n",
      "                                    - Discretized stays: 11\n",
      "                                    - Discretized samples: 787\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 12\n",
      "                                    - Discretized stays: 12\n",
      "                                    - Discretized samples: 957\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 13\n",
      "                                    - Discretized stays: 13\n",
      "                                    - Discretized samples: 1007\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 14\n",
      "                                    - Discretized stays: 14\n",
      "                                    - Discretized samples: 1092\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 15\n",
      "                                    - Discretized stays: 15\n",
      "                                    - Discretized samples: 1109\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 16\n",
      "                                    - Discretized stays: 16\n",
      "                                    - Discretized samples: 1130\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 17\n",
      "                                    - Discretized stays: 19\n",
      "                                    - Discretized samples: 1300\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 18\n",
      "                                    - Discretized stays: 20\n",
      "                                    - Discretized samples: 1353\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 19\n",
      "                                    - Discretized stays: 21\n",
      "                                    - Discretized samples: 1382\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 20\n",
      "                                    - Discretized stays: 22\n",
      "                                    - Discretized samples: 1418\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 21\n",
      "                                    - Discretized stays: 23\n",
      "                                    - Discretized samples: 1437\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 22\n",
      "                                    - Discretized stays: 24\n",
      "                                    - Discretized samples: 1457\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 23\n",
      "                                    - Discretized stays: 25\n",
      "                                    - Discretized samples: 1534\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 24\n",
      "                                    - Discretized stays: 26\n",
      "                                    - Discretized samples: 1581\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 25\n",
      "                                    - Discretized stays: 27\n",
      "                                    - Discretized samples: 1772\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 26\n",
      "                                    - Discretized stays: 28\n",
      "                                    - Discretized samples: 1816\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 27\n",
      "                                    - Discretized stays: 29\n",
      "                                    - Discretized samples: 1922\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 28\n",
      "                                    - Discretized stays: 30\n",
      "                                    - Discretized samples: 1987\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 29\n",
      "                                    - Discretized stays: 31\n",
      "                                    - Discretized samples: 2343\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 30\n",
      "                                    - Discretized stays: 32\n",
      "                                    - Discretized samples: 2369\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 31\n",
      "                                    - Discretized stays: 33\n",
      "                                    - Discretized samples: 2380\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 32\n",
      "                                    - Discretized stays: 34\n",
      "                                    - Discretized samples: 2694\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 33\n",
      "                                    - Discretized stays: 35\n",
      "                                    - Discretized samples: 2841\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 34\n",
      "                                    - Discretized stays: 36\n",
      "                                    - Discretized samples: 2878\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 35\n",
      "                                    - Discretized stays: 37\n",
      "                                    - Discretized samples: 2897\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 36\n",
      "                                    - Discretized stays: 38\n",
      "                                    - Discretized samples: 2916\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 37\n",
      "                                    - Discretized stays: 40\n",
      "                                    - Discretized samples: 3198\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 38\n",
      "                                    - Discretized stays: 41\n",
      "                                    - Discretized samples: 3219\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:40 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 39\n",
      "                                    - Discretized stays: 43\n",
      "                                    - Discretized samples: 3421\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 40\n",
      "                                    - Discretized stays: 44\n",
      "                                    - Discretized samples: 4016\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 41\n",
      "                                    - Discretized stays: 45\n",
      "                                    - Discretized samples: 4057\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 42\n",
      "                                    - Discretized stays: 46\n",
      "                                    - Discretized samples: 4175\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 43\n",
      "                                    - Discretized stays: 47\n",
      "                                    - Discretized samples: 4873\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 44\n",
      "                                    - Discretized stays: 48\n",
      "                                    - Discretized samples: 5005\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 45\n",
      "                                    - Discretized stays: 49\n",
      "                                    - Discretized samples: 5266\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 46\n",
      "                                    - Discretized stays: 50\n",
      "                                    - Discretized samples: 5375\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 47\n",
      "                                    - Discretized stays: 51\n",
      "                                    - Discretized samples: 5413\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 48\n",
      "                                    - Discretized stays: 53\n",
      "                                    - Discretized samples: 5639\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 49\n",
      "                                    - Discretized stays: 54\n",
      "                                    - Discretized samples: 5702\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 50\n",
      "                                    - Discretized stays: 55\n",
      "                                    - Discretized samples: 5714\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 51\n",
      "                                    - Discretized stays: 56\n",
      "                                    - Discretized samples: 5732\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 52\n",
      "                                    - Discretized stays: 57\n",
      "                                    - Discretized samples: 5782\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 53\n",
      "                                    - Discretized stays: 58\n",
      "                                    - Discretized samples: 5946\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 54\n",
      "                                    - Discretized stays: 59\n",
      "                                    - Discretized samples: 5957\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 55\n",
      "                                    - Discretized stays: 60\n",
      "                                    - Discretized samples: 5966\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 56\n",
      "                                    - Discretized stays: 61\n",
      "                                    - Discretized samples: 6008\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 57\n",
      "                                    - Discretized stays: 62\n",
      "                                    - Discretized samples: 6089\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 58\n",
      "                                    - Discretized stays: 63\n",
      "                                    - Discretized samples: 6126\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 59\n",
      "                                    - Discretized stays: 64\n",
      "                                    - Discretized samples: 6868\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 60\n",
      "                                    - Discretized stays: 65\n",
      "                                    - Discretized samples: 7175\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 61\n",
      "                                    - Discretized stays: 67\n",
      "                                    - Discretized samples: 7315\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 62\n",
      "                                    - Discretized stays: 68\n",
      "                                    - Discretized samples: 7342\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 63\n",
      "                                    - Discretized stays: 69\n",
      "                                    - Discretized samples: 7406\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 64\n",
      "                                    - Discretized stays: 70\n",
      "                                    - Discretized samples: 8237\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 65\n",
      "                                    - Discretized stays: 71\n",
      "                                    - Discretized samples: 8272\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 66\n",
      "                                    - Discretized stays: 72\n",
      "                                    - Discretized samples: 8482\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 67\n",
      "                                    - Discretized stays: 73\n",
      "                                    - Discretized samples: 8497\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 68\n",
      "                                    - Discretized stays: 75\n",
      "                                    - Discretized samples: 9032\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 69\n",
      "                                    - Discretized stays: 76\n",
      "                                    - Discretized samples: 9059\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 70\n",
      "                                    - Discretized stays: 77\n",
      "                                    - Discretized samples: 9114\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 71\n",
      "                                    - Discretized stays: 80\n",
      "                                    - Discretized samples: 9276\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 72\n",
      "                                    - Discretized stays: 81\n",
      "                                    - Discretized samples: 9327\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 73\n",
      "                                    - Discretized stays: 82\n",
      "                                    - Discretized samples: 9350\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 74\n",
      "                                    - Discretized stays: 84\n",
      "                                    - Discretized samples: 9376\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 75\n",
      "                                    - Discretized stays: 86\n",
      "                                    - Discretized samples: 9444\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 76\n",
      "                                    - Discretized stays: 87\n",
      "                                    - Discretized samples: 9458\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 77\n",
      "                                    - Discretized stays: 89\n",
      "                                    - Discretized samples: 9643\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:41 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 78\n",
      "                                    - Discretized stays: 103\n",
      "                                    - Discretized samples: 10489\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 79\n",
      "                                    - Discretized stays: 104\n",
      "                                    - Discretized samples: 10531\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 80\n",
      "                                    - Discretized stays: 105\n",
      "                                    - Discretized samples: 10637\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 81\n",
      "                                    - Discretized stays: 106\n",
      "                                    - Discretized samples: 10650\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 82\n",
      "                                    - Discretized stays: 107\n",
      "                                    - Discretized samples: 10776\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 83\n",
      "                                    - Discretized stays: 108\n",
      "                                    - Discretized samples: 10796\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 84\n",
      "                                    - Discretized stays: 109\n",
      "                                    - Discretized samples: 10832\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 85\n",
      "                                    - Discretized stays: 110\n",
      "                                    - Discretized samples: 10840\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 443  - Discretizing timeseries data:\n",
      "                                    - Discretized subjects: 86\n",
      "                                    - Discretized stays: 111\n",
      "                                    - Discretized samples: 10863\n",
      "                                    - Skipped subjects: 0\n",
      "INFO --- 06-19 22:08:42 : datasets/processors/__init__.py  : L 453  - Finalized for task DECOMP in directory:\n",
      "                                    - tmp/discretized/DECOMP\n"
     ]
    }
   ],
   "source": [
    "proc_reader = datasets.load_data(chunksize=75835,\n",
    "                                 source_path=TEST_DATA_DIR,\n",
    "                                 storage_path=\"./tmp\",\n",
    "                                 discretize=True,\n",
    "                                 deep_supervision=True,\n",
    "                                 task=\"DECOMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = proc_reader.read_samples(read_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO --- 06-19 22:08:45 : preprocessing/__init__.py  : L 171  - Fitting minmax_scaler to reader of size 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO --- 06-19 22:08:45 : preprocessing/__init__.py  : L 195  - Done computing new minmax_scaler.\n",
      "                                    - Saved in location tmp/discretized/DECOMP/minmax_scaler.pkl!\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit_reader(proc_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"X\"] = [scaler.transform(sample) for sample in dataset[\"X\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zeropad_samples(data):\n",
    "    max_len = max([x.shape[0] for x in data])\n",
    "    ret = [\n",
    "        np.concatenate([x, np.zeros((max_len - x.shape[0],) + x.shape[1:])],\n",
    "                        axis=0,\n",
    "                        dtype=np.float32) for x in data\n",
    "    ]\n",
    "    return np.atleast_3d(np.array(ret, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 845, 59)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(111, 845, 1)\n",
      "(111, 845, 1)\n"
     ]
    }
   ],
   "source": [
    "X = _zeropad_samples(dataset[\"X\"])\n",
    "M = _zeropad_samples(dataset[\"M\"])\n",
    "Y = _zeropad_samples(dataset[\"yds\"])\n",
    "print(X.shape)\n",
    "print(M.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 22:08:46.237030: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-19 22:08:46.237070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-19 22:08:46.238042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-19 22:08:46.244227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 22:08:47.106352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "class ExtendMask(Layer):\n",
    "    \"\"\" Inputs:      [X, M]\n",
    "        Output:      X\n",
    "        Output_mask: M\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, add_epsilon=False, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.add_epsilon = add_epsilon\n",
    "        super(ExtendMask, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, *args, **kwargs):\n",
    "        return x[0]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def compute_mask(self, input, *args, **kwargs):\n",
    "        if self.add_epsilon:\n",
    "            return input[1] + K.epsilon()\n",
    "        return input[1]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'add_epsilon': self.add_epsilon}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 22:08:47.743194: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.794060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.794306: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.795367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.795573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.795759: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.873595: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.873825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.874035: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-19 22:08:47.874180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3663 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "2024-06-19 22:08:48.669203: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "inputs = layers.Input(shape=(None, X.shape[2]))\n",
    "mask = layers.Input(shape=(None,), name='M')\n",
    "x = layers.Masking()(inputs)\n",
    "x = layers.LSTM(units=1000,\n",
    "                activation='tanh',\n",
    "                return_sequences=True,\n",
    "                recurrent_dropout=0,\n",
    "                dropout=0)(x)\n",
    "x = layers.LSTM(units=128, activation='tanh', dropout=0, return_sequences=True)(x)\n",
    "\n",
    "y = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "y = layers.TimeDistributed(layers.Dense(1, activation=\"sigmoid\"))(x)\n",
    "y = ExtendMask()([y, mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after TimeDistributed Dense layer: (None, None, 1)\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 22:08:55.947117: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-19 22:08:58.362716: I external/local_xla/xla/service/service.cc:168] XLA service 0x7b374a8cb550 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-19 22:08:58.362749: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-06-19 22:08:58.368420: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718827738.540274 1184798 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 126ms/step - loss: 0.6951\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.6888\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.6825\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.6778\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.6722\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.6679\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 1s 120ms/step - loss: 0.6632\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.6574\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.6524\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.6460\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.6420\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6364\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.6310\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.6273\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.6222\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.6175\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.6120\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.6063\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.6027\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.5986\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.5930\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.5899\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.5853\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.5828\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.5738\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.5734\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.5653\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.5630\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.5579\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.5546\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.5474\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.5442\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.5427\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.5363\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 0.5291\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 0.5281\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.5249\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.5200\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 1s 115ms/step - loss: 0.5136\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 1s 120ms/step - loss: 0.5088\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.5034\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.5012\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4979\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.4951\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.4882\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4834\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.4810\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.4746\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.4734\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 1s 117ms/step - loss: 0.4712\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4633\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.4627\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 0.4554\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.4499\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.4471\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4476\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4452\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.4359\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.4338\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.4285\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.4256\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 0.4254\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 0.4172\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.4211\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.4092\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.4049\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.4024\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.4058\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.3929\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.3924\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.3898\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.3897\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3828\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.3786\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3743\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 1s 113ms/step - loss: 0.3769\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.3742\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.3670\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3610\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.3558\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.3570\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.3498\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3484\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3454\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.3377\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3364\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.3451\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.3351\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.3297\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.3245\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.3215\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.3200\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.3165\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.3150\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3110\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.3236\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3065\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.3065\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.3010\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.3005\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2972\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.2899\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.2948\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2851\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.2898\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2837\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.2883\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.2858\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.2754\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.2777\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.2717\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.2750\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.2663\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.2768\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2647\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.2621\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.2611\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.2595\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.2563\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.2571\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2574\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.2478\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.2444\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.2528\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.2592\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2415\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.2407\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.2414\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.2376\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.2335\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.2423\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.2351\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.2338\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.2329\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2345\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.2307\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.2347\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.2351\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2387\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.2252\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.2215\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2218\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2280\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.2212\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.2232\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2215\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2352\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2165\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.2244\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.2129\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.2290\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.2153\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.2218\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2156\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.2164\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.2209\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2051\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2076\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.2176\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.2266\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.2211\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.2113\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2159\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2046\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.2019\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.2084\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2021\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.1979\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.2019\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.2043\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2241\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.2006\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2305\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.1981\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2024\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2005\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.1980\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.2021\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.2059\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.2028\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.2040\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.2113\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.1995\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.2051\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2026\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.1968\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.2015\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.2030\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1990\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.1969\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.1967\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1992\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1998\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1997\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.1993\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.2024\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.1988\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2006\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1944\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.2152\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2009\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.2090\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2057\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.2191\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.1979\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.1992\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.2096\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.2202\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.2081\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.1991\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.1970\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.1929\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1976\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.2099\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.1920\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.1941\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1956\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.2241\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1912\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.1935\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.1929\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.2153\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2164\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1919\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 133ms/step - loss: 0.1982\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.1964\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.1920\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1883\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.1961\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1954\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2139\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2055\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1990\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.2044\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.2048\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.1938\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2058\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2044\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.1948\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.2015\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.1891\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1819\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.1883\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1879\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.2046\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2033\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1959\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.2003\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.1879\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2027\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1969\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.1951\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2111\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.1950\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.1957\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1962\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.2276\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1852\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.1881\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.2113\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1852\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1876\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1935\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.2009\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.1981\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.1943\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.1826\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.1882\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.2144\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.2055\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.2034\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1990\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.2175\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2128\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.1920\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1924\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2041\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1919\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1946\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1883\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.1861\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1895\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1877\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 0.1874\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1859\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 0.1881\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1871\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1849\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.1880\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1949\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.1850\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1884\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.1823\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.1939\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.1992\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.1910\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1876\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.1946\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1967\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.1862\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1879\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1860\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.1861\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.1998\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1950\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1996\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.1975\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.1906\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1817\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 0.1884\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.1865\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2064\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 1s 116ms/step - loss: 0.1869\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.1911\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.1888\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1926\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.2112\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1896\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.1905\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1869\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1988\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.1852\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.1811\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1877\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.1994\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1862\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.1982\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.1834\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.1853\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.1832\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1880\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1955\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.1908\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1963\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2017\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.1903\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1845\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.1953\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1961\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1822\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2041\n",
      "Epoch 342/1000\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.1801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[inputs, mask], outputs\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(clipvalue\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Shape after TimeDistributed Dense layer: {y.shape}\")\n",
    "model = models.Model(inputs=[inputs, mask], outputs=y)\n",
    "model.compile(optimizer=Adam(clipvalue=1.0, learning_rate=0.000001), loss=\"binary_crossentropy\")\n",
    "history = model.fit([X, M], Y, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators.tf2 import TFGenerator\n",
    "train_generator = TFGenerator(reader=proc_reader,\n",
    "                              scaler=scaler,\n",
    "                              batch_size=32,\n",
    "                              deep_supervision=True,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 16:17:38.883787: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-18 16:17:41.521981: I external/local_xla/xla/service/service.cc:168] XLA service 0x72478e485e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-18 16:17:41.522018: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-06-18 16:17:41.526693: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718720261.664122  570111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 9s 125ms/step - loss: 0.6625\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 2s 660ms/step - loss: 0.6630\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 2s 653ms/step - loss: 0.6607\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.6591\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 2s 676ms/step - loss: 0.6513\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 0.6528\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 2s 771ms/step - loss: 0.6482\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 0.6454\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 0.6417\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 0.6377\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 0.6350\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 2s 654ms/step - loss: 0.6264\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.6271\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 2s 644ms/step - loss: 0.6258\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 0.6268\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 0.6169\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.6209\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 0.6124\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.6089\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 2s 626ms/step - loss: 0.6050\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 2s 632ms/step - loss: 0.6031\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 2s 763ms/step - loss: 0.5997\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 0.5953\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 2s 695ms/step - loss: 0.5952\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 2s 809ms/step - loss: 0.5908\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 2s 772ms/step - loss: 0.5967\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 2s 687ms/step - loss: 0.5828\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 2s 659ms/step - loss: 0.5837\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 2s 672ms/step - loss: 0.5837\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 2s 632ms/step - loss: 0.5749\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 2s 783ms/step - loss: 0.5723\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.5770\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 2s 654ms/step - loss: 0.5649\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 0.5666\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 2s 705ms/step - loss: 0.5627\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 2s 658ms/step - loss: 0.5610\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 2s 704ms/step - loss: 0.5555\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 2s 713ms/step - loss: 0.5525\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 2s 655ms/step - loss: 0.5498\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.5463\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 2s 707ms/step - loss: 0.5464\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 2s 657ms/step - loss: 0.5460\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.5394\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 2s 803ms/step - loss: 0.5341\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.5339\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 2s 766ms/step - loss: 0.5313\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 2s 801ms/step - loss: 0.5328\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 2s 699ms/step - loss: 0.5159\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 0.5315\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.5149\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 2s 648ms/step - loss: 0.5188\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 0.5141\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 2s 805ms/step - loss: 0.5106\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 2s 683ms/step - loss: 0.5077\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.5096\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.5022\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.5042\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 2s 680ms/step - loss: 0.5068\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 0.4923\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 2s 640ms/step - loss: 0.4932\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.4864\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 2s 766ms/step - loss: 0.4845\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 2s 656ms/step - loss: 0.4862\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 0.4889\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 2s 780ms/step - loss: 0.4792\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 0.4746\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.4743\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 2s 770ms/step - loss: 0.4800\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 2s 681ms/step - loss: 0.4582\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 0.4695\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.4586\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 2s 704ms/step - loss: 0.4575\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 2s 686ms/step - loss: 0.4631\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 2s 678ms/step - loss: 0.4495\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.4503\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.4519\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 0.4469\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.4456\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 2s 514ms/step - loss: 0.4426\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.4336\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 0.4391\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.4387\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.4266\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.4354\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.4232\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.4144\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.4326\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 0.4081\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 0.4252\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.4272\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.4146\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.4054\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.3978\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 2s 630ms/step - loss: 0.3967\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.4224\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 0.3965\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.3963\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.4135\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.3905\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 2s 425ms/step - loss: 0.3813\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.3842\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 2s 525ms/step - loss: 0.3853\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 0.3928\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.3773\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.3851\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 0.3663\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 1s 453ms/step - loss: 0.3759\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.3599\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.3659\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 0.3789\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 0.3612\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.3657\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 2s 684ms/step - loss: 0.3544\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 2s 634ms/step - loss: 0.3453\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 0.3609\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 2s 705ms/step - loss: 0.3614\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 2s 529ms/step - loss: 0.3434\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 0.3604\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 0.3267\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.3369\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 2s 657ms/step - loss: 0.3330\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 2s 632ms/step - loss: 0.3375\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.3202\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 0.3389\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 0.3220\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 0.3384\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 0.3146\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.3209\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 0.3304\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.3231\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.3187\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 0.3266\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.3231\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.3015\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 0.3132\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 0.3017\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 0.3211\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.2917\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 0.3060\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 2s 477ms/step - loss: 0.3193\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.2810\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.2980\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.2851\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.2921\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 0.2928\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 0.2924\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.2931\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 1s 516ms/step - loss: 0.2752\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.2902\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.3102\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 0.2699\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 2s 640ms/step - loss: 0.2711\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 0.2675\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 0.2918\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 0.2675\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.2626\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 0.2719\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 2s 481ms/step - loss: 0.2888\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 0.2482\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.2706\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.2754\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 2s 680ms/step - loss: 0.2877\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 2s 666ms/step - loss: 0.2593\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 0.2510\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.2693\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 2s 529ms/step - loss: 0.2472\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 0.2257\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.2420\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 2s 697ms/step - loss: 0.2456\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 2s 623ms/step - loss: 0.2323\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 2s 644ms/step - loss: 0.2515\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 2s 704ms/step - loss: 0.2317\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.2646\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 0.2137\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 2s 706ms/step - loss: 0.2471\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 2s 650ms/step - loss: 0.2295\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 2s 630ms/step - loss: 0.2168\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.2344\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.2168\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.2517\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.2336\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 2s 626ms/step - loss: 0.2231\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 2s 700ms/step - loss: 0.2243\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 2s 696ms/step - loss: 0.2653\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.2172\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 0.2061\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 2s 695ms/step - loss: 0.2362\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 2s 713ms/step - loss: 0.2221\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 2s 693ms/step - loss: 0.2208\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.2118\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.2090\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 2s 801ms/step - loss: 0.2455\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 2s 752ms/step - loss: 0.2065\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 0.2330\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 2s 750ms/step - loss: 0.2569\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.2017\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 2s 656ms/step - loss: 0.2270\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 0.2174\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 2s 641ms/step - loss: 0.2187\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 2s 644ms/step - loss: 0.2255\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.2107\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 2s 677ms/step - loss: 0.2153\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.1987\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 2s 635ms/step - loss: 0.1971\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.2140\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 2s 683ms/step - loss: 0.2260\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 3s 879ms/step - loss: 0.1971\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 2s 765ms/step - loss: 0.2267\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.1701\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.2212\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 0.2291\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 2s 651ms/step - loss: 0.1824\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.1982\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 2s 658ms/step - loss: 0.1889\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 2s 669ms/step - loss: 0.1881\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 2s 673ms/step - loss: 0.2248\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 2s 763ms/step - loss: 0.1620\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 2s 835ms/step - loss: 0.2667\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 3s 753ms/step - loss: 0.1800\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 2s 861ms/step - loss: 0.2252\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 2s 668ms/step - loss: 0.1935\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 0.2434\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.2000\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 0.1847\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 0.2058\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 2s 805ms/step - loss: 0.2126\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 2s 768ms/step - loss: 0.2112\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 2s 820ms/step - loss: 0.1750\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 3s 863ms/step - loss: 0.2118\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 2s 688ms/step - loss: 0.2125\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 0.1703\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 3s 841ms/step - loss: 0.2353\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 2s 692ms/step - loss: 0.2019\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 2s 644ms/step - loss: 0.2218\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 2s 803ms/step - loss: 0.1951\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.1792\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 2s 679ms/step - loss: 0.2117\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.2644\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.2038\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 2s 637ms/step - loss: 0.1791\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 0.2301\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 0.1758\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.2326\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.2054\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 2s 676ms/step - loss: 0.1888\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 2s 661ms/step - loss: 0.2158\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 0.1984\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 2s 764ms/step - loss: 0.1837\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.1947\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 2s 658ms/step - loss: 0.2045\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.2057\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 2s 686ms/step - loss: 0.2244\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 2s 661ms/step - loss: 0.1927\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.2018\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 0.1938\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.1832\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 2s 780ms/step - loss: 0.2189\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 2s 658ms/step - loss: 0.2033\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 0.1820\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.2254\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 0.1639\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 0.2373\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 2s 689ms/step - loss: 0.1772\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 2s 686ms/step - loss: 0.2054\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 2s 653ms/step - loss: 0.1655\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 2s 658ms/step - loss: 0.2146\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 3s 889ms/step - loss: 0.2005\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 3s 997ms/step - loss: 0.1946\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 3s 866ms/step - loss: 0.2090\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1743\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2001\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2101\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.1959\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2137\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.2017\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1884\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1865\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.1862\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2205\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 3s 995ms/step - loss: 0.2240\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1587\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2072\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 2s 705ms/step - loss: 0.2049\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 2s 705ms/step - loss: 0.2188\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 2s 656ms/step - loss: 0.1727\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 2s 792ms/step - loss: 0.2032\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 0.1914\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 3s 887ms/step - loss: 0.2175\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 3s 838ms/step - loss: 0.1610\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 3s 901ms/step - loss: 0.1694\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.2150\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 0.2048\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 2s 659ms/step - loss: 0.1634\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.1922\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 2s 662ms/step - loss: 0.1932\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 0.2192\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.1964\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 0.2156\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.1840\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.1826\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.2014\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.1896\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1990\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 2s 497ms/step - loss: 0.1908\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 1s 513ms/step - loss: 0.1849\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 0.1982\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 0.1912\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 0.1934\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.1981\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.2345\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.1607\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.2086\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.1654\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 2s 477ms/step - loss: 0.1913\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.2284\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 0.1852\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 0.1978\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.1928\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 0.1886\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 0.1855\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 2s 634ms/step - loss: 0.1896\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2004\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1727\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 3s 903ms/step - loss: 0.1863\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2193\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1551\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2472\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1654\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2220\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 3s 982ms/step - loss: 0.1770\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 2s 865ms/step - loss: 0.2016\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 3s 900ms/step - loss: 0.1898\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2259\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 3s 907ms/step - loss: 0.1753\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 3s 897ms/step - loss: 0.1937\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.1766\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.2484\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 3s 866ms/step - loss: 0.1795\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 0.1855\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 3s 844ms/step - loss: 0.1784\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 3s 931ms/step - loss: 0.2045\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1660\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 3s 913ms/step - loss: 0.1897\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.2391\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 2s 833ms/step - loss: 0.1895\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.1973\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 3s 925ms/step - loss: 0.1607\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 2s 861ms/step - loss: 0.2032\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 3s 853ms/step - loss: 0.1905\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 3s 831ms/step - loss: 0.2049\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 2s 700ms/step - loss: 0.2007\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.1737\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 2s 680ms/step - loss: 0.1958\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 0.1610\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 2s 703ms/step - loss: 0.2043\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 2s 821ms/step - loss: 0.1771\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 2s 697ms/step - loss: 0.2044\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1716\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 3s 934ms/step - loss: 0.1831\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 2s 801ms/step - loss: 0.1966\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 2s 847ms/step - loss: 0.1987\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 3s 970ms/step - loss: 0.2099\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 2s 761ms/step - loss: 0.1916\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 2s 752ms/step - loss: 0.1748\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 2s 686ms/step - loss: 0.2125\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.1996\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.1916\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 2s 696ms/step - loss: 0.2238\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 2s 673ms/step - loss: 0.2020\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1957\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.1829\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 2s 905ms/step - loss: 0.2031\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 2s 789ms/step - loss: 0.1998\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 2s 662ms/step - loss: 0.1887\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 0.2027\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.2041\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.1830\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 2s 688ms/step - loss: 0.1869\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 0.2162\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.1815\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 0.1706\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.2076\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.1788\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 2s 711ms/step - loss: 0.2077\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 2s 695ms/step - loss: 0.1908\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 2s 783ms/step - loss: 0.2112\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 2s 759ms/step - loss: 0.1566\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 3s 933ms/step - loss: 0.1976\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 3s 891ms/step - loss: 0.1601\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 2s 745ms/step - loss: 0.2017\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 2s 817ms/step - loss: 0.1667\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 2s 884ms/step - loss: 0.1978\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 2s 693ms/step - loss: 0.2125\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 2s 821ms/step - loss: 0.1904\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 2s 766ms/step - loss: 0.1709\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.2094\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 2s 716ms/step - loss: 0.1923\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 2s 791ms/step - loss: 0.1995\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.2229\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 3s 882ms/step - loss: 0.1841\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 3s 910ms/step - loss: 0.2032\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.1854\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 2s 465ms/step - loss: 0.1704\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 3s 877ms/step - loss: 0.1884\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.2338\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 2s 664ms/step - loss: 0.1611\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.1861\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 2s 635ms/step - loss: 0.1982\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 2s 656ms/step - loss: 0.1892\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 0.1874\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 2s 677ms/step - loss: 0.1600\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.1967\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 2s 632ms/step - loss: 0.2068\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 0.1832\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 2s 666ms/step - loss: 0.2114\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 0.1826\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 0.1673\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 0.1776\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 0.1948\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.1711\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 2s 664ms/step - loss: 0.1691\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.2028\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 0.1814\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.1980\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.1906\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 0.1864\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.2070\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.1949\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.2098\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 1s 486ms/step - loss: 0.2132\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.1580\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 0.1960\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 0.1778\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 0.1867\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 2s 698ms/step - loss: 0.1815\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.1644\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1772\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.1894\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.2024\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.1728\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 0.2052\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.1744\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 0.1971\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1469\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 2s 468ms/step - loss: 0.2123\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.2171\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.2056\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.1775\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 0.2002\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.2061\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 0.1644\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 2s 498ms/step - loss: 0.1917\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.1995\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 0.1682\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 0.1962\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 0.1876\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 0.1900\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1803\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.1874\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.1638\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.1979\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.1810\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 2s 651ms/step - loss: 0.1800\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.1787\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 0.2118\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 0.1811\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 2s 652ms/step - loss: 0.2038\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.1719\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 2s 678ms/step - loss: 0.1426\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 0.2358\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.1963\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.1904\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.1801\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 0.1705\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 1s 515ms/step - loss: 0.2278\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 0.1753\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.1893\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.1663\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.1936\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1790\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 0.1906\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.1841\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.1880\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.2247\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.1406\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 2s 554ms/step - loss: 0.2233\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 0.1564\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 0.1866\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1906\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 0.1905\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 2s 660ms/step - loss: 0.1592\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 2s 634ms/step - loss: 0.1814\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 0.1915\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 0.1603\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 0.2273\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 2s 653ms/step - loss: 0.1822\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 2s 667ms/step - loss: 0.1658\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 0.1681\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.1835\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 0.1646\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 2s 529ms/step - loss: 0.1765\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 1s 502ms/step - loss: 0.2064\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.1640\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 2s 468ms/step - loss: 0.1827\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1614\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 0.1891\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.1970\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.2033\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 0.1595\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.1786\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.1898\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 0.1529\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.2144\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 0.1965\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 2s 822ms/step - loss: 0.1777\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 2s 770ms/step - loss: 0.1610\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.2327\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 2s 778ms/step - loss: 0.1565\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 2s 685ms/step - loss: 0.1896\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 0.1874\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 2s 655ms/step - loss: 0.2005\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.1920\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.1582\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 2s 714ms/step - loss: 0.1832\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 2s 623ms/step - loss: 0.1650\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1855\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 0.1664\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 2s 515ms/step - loss: 0.2051\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.1589\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.1839\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1926\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1578\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 0.1901\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 2s 484ms/step - loss: 0.1729\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.1471\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 2s 517ms/step - loss: 0.2047\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 2s 488ms/step - loss: 0.1465\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1698\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 0.2143\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.2052\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.1785\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.1917\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 0.1849\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.1968\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.1670\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.1794\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 0.1781\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1818\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.1562\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.2068\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 0.1872\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 0.1503\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 2s 490ms/step - loss: 0.1687\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.2206\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1848\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 2s 525ms/step - loss: 0.2101\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 1s 491ms/step - loss: 0.1621\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1855\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1644\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1788\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 1s 500ms/step - loss: 0.1749\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 2s 461ms/step - loss: 0.2019\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 2s 495ms/step - loss: 0.1713\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 1s 493ms/step - loss: 0.1850\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 2s 462ms/step - loss: 0.2014\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.1546\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 0.1917\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1626\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 1s 472ms/step - loss: 0.2005\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 2s 517ms/step - loss: 0.1719\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 2s 707ms/step - loss: 0.1852\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 2s 835ms/step - loss: 0.1749\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 2s 765ms/step - loss: 0.1975\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 2s 703ms/step - loss: 0.1572\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 2s 634ms/step - loss: 0.1948\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.1913\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.1498\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 0.1769\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 2s 495ms/step - loss: 0.1585\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 0.1714\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1706\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 2s 484ms/step - loss: 0.1917\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 2s 482ms/step - loss: 0.1949\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 0.1646\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 1s 537ms/step - loss: 0.1662\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.1731\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.1964\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.1602\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.1740\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 2s 486ms/step - loss: 0.1663\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 0.2067\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 0.1815\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.2246\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 2s 462ms/step - loss: 0.1788\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1977\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 2s 582ms/step - loss: 0.2015\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.1969\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.1935\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1553\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1595\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 0.2027\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.1492\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.1780\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.2001\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 2s 517ms/step - loss: 0.1657\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 2s 492ms/step - loss: 0.1729\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 1s 529ms/step - loss: 0.1946\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 0.2038\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 0.1727\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.1482\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.1829\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.1562\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 0.1918\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 2s 652ms/step - loss: 0.2006\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 1s 523ms/step - loss: 0.2268\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.1605\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 0.1935\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 0.1497\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 1s 519ms/step - loss: 0.1960\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.2059\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1510\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.1553\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 0.1795\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.1687\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.1969\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 0.1972\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.1898\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.1909\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.1985\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 2s 461ms/step - loss: 0.1687\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 0.1857\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.1880\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.1717\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 2s 490ms/step - loss: 0.1628\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 0.1675\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1792\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 0.1824\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.2039\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 0.1441\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 1s 457ms/step - loss: 0.2156\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1711\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.1562\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 1s 491ms/step - loss: 0.1839\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 1s 517ms/step - loss: 0.1549\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 0.1742\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1793\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 2s 498ms/step - loss: 0.1571\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1839\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.1614\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.1878\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 2s 528ms/step - loss: 0.1901\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 0.2143\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 1s 525ms/step - loss: 0.1875\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 0.1853\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 1s 519ms/step - loss: 0.1422\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 2s 486ms/step - loss: 0.1711\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.1736\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 1s 452ms/step - loss: 0.1832\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 0.1743\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.2039\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.2065\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 0.1435\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 0.2039\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 2s 444ms/step - loss: 0.1547\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 1s 522ms/step - loss: 0.1886\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 0.1691\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.1593\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 1s 526ms/step - loss: 0.1835\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.1748\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.1888\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 0.1778\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 0.1746\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 2s 565ms/step - loss: 0.1675\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.1835\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.1631\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 0.1776\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 1s 501ms/step - loss: 0.2018\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 0.1630\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 0.1761\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 0.2082\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 1s 474ms/step - loss: 0.1573\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 0.1703\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1543\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.1921\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1812\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 1s 508ms/step - loss: 0.1422\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 1s 508ms/step - loss: 0.1876\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 0.1655\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 2s 481ms/step - loss: 0.1681\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 0.1662\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.1685\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1577\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 1s 487ms/step - loss: 0.1773\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.1854\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 2s 479ms/step - loss: 0.1563\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1765\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 1s 503ms/step - loss: 0.1745\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1649\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 0.1563\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.1761\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.1666\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 0.1644\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 1s 487ms/step - loss: 0.1757\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 0.1843\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 0.1796\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 1s 510ms/step - loss: 0.1765\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.1714\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 0.1526\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 1s 456ms/step - loss: 0.1612\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 2s 446ms/step - loss: 0.1840\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.1588\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 1s 490ms/step - loss: 0.1847\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 0.1618\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.1821\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 1s 533ms/step - loss: 0.1498\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.1905\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 0.1638\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 2s 476ms/step - loss: 0.1763\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1611\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 1s 527ms/step - loss: 0.1817\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.1680\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 2s 554ms/step - loss: 0.1668\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.1873\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 1s 457ms/step - loss: 0.1791\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.1639\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 1s 502ms/step - loss: 0.1881\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1685\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1855\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 1s 522ms/step - loss: 0.1565\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 2s 492ms/step - loss: 0.1624\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.1905\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1749\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.1705\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 0.1684\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.1561\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 1s 486ms/step - loss: 0.1707\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.1670\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.1946\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 1s 507ms/step - loss: 0.1763\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.1647\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 0.1531\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 1s 516ms/step - loss: 0.1674\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 1s 480ms/step - loss: 0.1663\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 2s 441ms/step - loss: 0.1785\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 1s 480ms/step - loss: 0.1823\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1516\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 0.1281\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.2244\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 1s 461ms/step - loss: 0.1634\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 2s 485ms/step - loss: 0.1599\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 2s 473ms/step - loss: 0.1723\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 0.1712\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 2s 473ms/step - loss: 0.1728\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 0.1821\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 1s 491ms/step - loss: 0.1522\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 2s 496ms/step - loss: 0.2044\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 1s 496ms/step - loss: 0.1738\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 0.1827\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 2s 486ms/step - loss: 0.1482\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 1s 454ms/step - loss: 0.1897\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 2s 495ms/step - loss: 0.1559\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 0.1773\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 2s 495ms/step - loss: 0.1596\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.1534\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 0.1451\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1683\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 1s 509ms/step - loss: 0.1566\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.2185\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 1s 434ms/step - loss: 0.1498\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 0.1769\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 2s 445ms/step - loss: 0.1674\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.1668\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 0.1516\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.2076\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 1s 456ms/step - loss: 0.1812\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 1s 474ms/step - loss: 0.1392\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 0.1862\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 1s 447ms/step - loss: 0.1407\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 1s 515ms/step - loss: 0.1832\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 0.1401\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 1s 480ms/step - loss: 0.1514\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 1s 503ms/step - loss: 0.1824\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 2s 566ms/step - loss: 0.1751\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 0.1751\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.1429\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 2s 554ms/step - loss: 0.1859\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.1583\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 2s 497ms/step - loss: 0.1490\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1705\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.1659\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 1s 452ms/step - loss: 0.1916\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 1s 504ms/step - loss: 0.1847\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 2s 464ms/step - loss: 0.1750\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1660\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1514\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1722\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1788\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 0.2055\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 0.1452\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 1s 543ms/step - loss: 0.1530\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 1s 500ms/step - loss: 0.2122\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.1705\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.1597\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 0.1502\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1884\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1552\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.1638\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.2254\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 1s 487ms/step - loss: 0.1217\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 1s 428ms/step - loss: 0.1778\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 0.1767\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.1301\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.1813\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 1s 467ms/step - loss: 0.1662\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 0.1557\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1526\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.1831\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.1615\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.1789\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.1766\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.1754\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1575\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.2018\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 0.1676\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.1482\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 1s 478ms/step - loss: 0.1485\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.1443\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.1698\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 1s 430ms/step - loss: 0.1534\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 0.1556\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 1s 511ms/step - loss: 0.2007\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.1453\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 1s 519ms/step - loss: 0.1581\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 0.1807\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1477\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 0.1896\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 0.1741\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 1s 507ms/step - loss: 0.1293\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1715\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 0.1555\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 0.1931\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.1713\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.1582\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 1s 492ms/step - loss: 0.1604\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 2s 500ms/step - loss: 0.1666\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.1396\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 0.1673\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 0.1511\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.1695\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1567\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.1475\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1630\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.2211\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1380\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 1s 507ms/step - loss: 0.1996\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 1s 502ms/step - loss: 0.1794\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 0.1628\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 1s 493ms/step - loss: 0.1703\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.1647\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.1714\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 2s 487ms/step - loss: 0.1567\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 1s 490ms/step - loss: 0.1695\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 0.1729\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 2s 487ms/step - loss: 0.1398\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.1705\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 0.1332\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.1609\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 1s 529ms/step - loss: 0.1652\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1491\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 2s 562ms/step - loss: 0.1577\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.1583\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 0.1564\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 0.1577\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 0.2023\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.1355\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 1s 538ms/step - loss: 0.1568\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 1s 490ms/step - loss: 0.1541\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 1s 463ms/step - loss: 0.1797\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.1528\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 1s 478ms/step - loss: 0.1636\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 0.1448\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 0.1611\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 0.1849\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.1635\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.1600\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.1756\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 0.1626\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 1s 497ms/step - loss: 0.1880\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 2s 452ms/step - loss: 0.1791\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 1s 485ms/step - loss: 0.1472\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.1608\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 2s 454ms/step - loss: 0.1668\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 1s 472ms/step - loss: 0.1850\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 0.1669\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 0.1682\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.1780\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 1s 472ms/step - loss: 0.1661\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.1562\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 1s 526ms/step - loss: 0.1976\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 0.1524\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.1735\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.1348\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.1677\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.1656\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 1s 493ms/step - loss: 0.1312\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 1s 486ms/step - loss: 0.1775\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1615\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 1s 459ms/step - loss: 0.1324\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 2s 478ms/step - loss: 0.1674\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.1664\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1380\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.1731\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.1554\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.1932\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 1s 487ms/step - loss: 0.1552\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.1497\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.1630\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1233\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 2s 564ms/step - loss: 0.1865\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 0.1494\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 1s 521ms/step - loss: 0.1801\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 2s 500ms/step - loss: 0.1337\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1584\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 0.1835\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 1s 454ms/step - loss: 0.1684\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 2s 497ms/step - loss: 0.1389\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 0.1584\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.1917\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 2s 478ms/step - loss: 0.1472\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 2s 484ms/step - loss: 0.1632\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 1s 457ms/step - loss: 0.1665\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.1444\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 0.2095\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 2s 496ms/step - loss: 0.1479\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 2s 485ms/step - loss: 0.1562\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.1682\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 0.1325\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 1s 516ms/step - loss: 0.1677\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 1s 467ms/step - loss: 0.1253\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.1691\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 0.1459\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 0.1558\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 1s 539ms/step - loss: 0.2113\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 1s 461ms/step - loss: 0.1626\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 1s 503ms/step - loss: 0.1614\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 0.1977\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 1s 513ms/step - loss: 0.1261\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 2s 525ms/step - loss: 0.1507\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.1601\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 2s 463ms/step - loss: 0.1744\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 1s 512ms/step - loss: 0.1321\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.1327\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.1765\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 1s 486ms/step - loss: 0.1616\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 0.1632\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.1667\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1702\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.1222\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 0.1731\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 1s 472ms/step - loss: 0.1265\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 2s 563ms/step - loss: 0.1552\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.1803\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 1s 493ms/step - loss: 0.1254\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.1551\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 2s 450ms/step - loss: 0.1573\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 2s 493ms/step - loss: 0.1640\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.1544\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.1339\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 1s 459ms/step - loss: 0.1568\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.1715\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.1560\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 0.1493\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.1681\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.1648\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.1509\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 2s 446ms/step - loss: 0.1543\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.1923\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 1s 459ms/step - loss: 0.1517\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.1518\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 1s 528ms/step - loss: 0.1509\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 0.1628\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 1s 441ms/step - loss: 0.1423\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 0.1471\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.1532\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 1s 487ms/step - loss: 0.1795\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.1056\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 1s 490ms/step - loss: 0.1716\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 2s 529ms/step - loss: 0.1508\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 1s 551ms/step - loss: 0.1416\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 0.1649\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 0.1690\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.1409\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.1827\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 1s 494ms/step - loss: 0.1423\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 1s 405ms/step - loss: 0.1794\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 2s 488ms/step - loss: 0.1276\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 1s 502ms/step - loss: 0.1601\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.1515\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 2s 485ms/step - loss: 0.1727\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 0.1603\n"
     ]
    }
   ],
   "source": [
    "model = models.Model(inputs=[inputs, mask], outputs=y)\n",
    "model.compile(optimizer=Adam(clipvalue=1.0, learning_rate=0.000001), loss=\"binary_crossentropy\", metrics=[\"roc_auc\", \"pr_auc\"])\n",
    "history = model.fit(train_generator, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tf2.lstm import LSTMNetwork\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = LSTMNetwork(1000,\n",
    "                    59,\n",
    "                    recurrent_dropout=0.,\n",
    "                    output_dim=1,\n",
    "                    depth=3,\n",
    "                    final_activation='sigmoid')\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001, clipvalue=1.0), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
