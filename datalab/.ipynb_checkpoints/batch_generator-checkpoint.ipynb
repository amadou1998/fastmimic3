{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1a96b8",
   "metadata": {},
   "source": [
    "# Batch Generator for MIMIC-III\n",
    "This notebook is dedicated to reproducing the batch generator, which calls on the normalizer and discretizer to process each subject dataframe into smaller batches. The batch generator is spread out over several deeply nested function in the benchmark codebase, but we would like to fuse it into a self-contained set of function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ecd95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 10:10:58.842453: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-29 10:10:58.842496: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from preprocessing.mimic import Discretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c8471",
   "metadata": {},
   "source": [
    "### Data Dependencies\n",
    "The Notebook will require an unprocessed timeseries as generated by the the Preprocessor class, which makes the task data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0c718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(Path(\"resources\", \"10011_episode1_timeseries.csv\")).set_index('Hours')\n",
    "y_df = pd.read_csv(Path(\"resources\", \"listfile.csv\"))\n",
    "with open(Path(\"resources\", \"discretizer_config.json\")) as file: \n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e98599",
   "metadata": {},
   "source": [
    "### Reading the Series\n",
    "Analoguesly to the benchmark implementation, we will read the timeseries into subsampled windows. The lower end of the dataframe is being expanded on each iteration and paired with the complementary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55bc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_timeseries(X_df, y_df):\n",
    "    Xs = list()\n",
    "    ys = list()\n",
    "    ts = list()\n",
    "    names = list()\n",
    "    \n",
    "    for index in range(len(y_df)):  \n",
    "\n",
    "        if index < 0 or index >= len(y_df):\n",
    "            raise ValueError(\"Index must be from 0 (inclusive) to number of examples (exclusive).\")\n",
    "\n",
    "        name = y_df.iloc[index][0]\n",
    "        t = y_df.iloc[index][1]\n",
    "        y = y_df.iloc[index][2]\n",
    "        (X, header) = X_df[X_df.index < t + 1e-6], list(X_df.columns)\n",
    "\n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "        ts.append(t)\n",
    "        names.append(name)\n",
    "        header = header\n",
    "        \n",
    "    return Xs, ys, ts, names, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4003ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be00f9d5",
   "metadata": {},
   "source": [
    "### Processing\n",
    "Each of the read windows needs to be discretized and scaled. This has been found to be the most time intensive step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d816a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "remaining = 10\n",
    "chunk_size = 12\n",
    "discretizer = Discretizer(config)\n",
    "\n",
    "\n",
    "def process_batch(Xs, ts):\n",
    "    data = [discretizer.transform(X, end=t) for (X, t) in zip(Xs, ts)]\n",
    "        \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f48853",
   "metadata": {},
   "source": [
    "### Shuffling\n",
    "Depending on the application, shuffling the data can enhance the prediction capabilities. The listed nature of our data, label pairs makes this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b80e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(data, batch_size):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert len(data) >= 2\n",
    "    if type(data[0][0]) == pd.DataFrame:\n",
    "        data[0] = [x.values for x in data[0]]\n",
    "    # Passed data is paralell list(X, y, ts)  \n",
    "    data = list(zip(*data))\n",
    "    # Data is now put into tuples, list(tuple1, tuple2, tuple3)\n",
    "    random.shuffle(data)\n",
    "\n",
    "    residual_length = len(data) % batch_size\n",
    "    head = data[:len(data) - residual_length]\n",
    "    residual = data[len(data) - residual_length:]\n",
    "\n",
    "    # Sort by length of X\n",
    "    head.sort(key=(lambda x: x[0].shape[0]))\n",
    "    \n",
    "\n",
    "    batches = [head[i: i+batch_size] for i in range(0, len(head), batch_size)]\n",
    "\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    batches += residual\n",
    "    batches = list(zip(*batches))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228da764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_zeropadding(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dtype = data[0].dtype\n",
    "    max_len = max([x.shape[0] for x in data])\n",
    "    ret = [np.concatenate([x, np.zeros((max_len - x.shape[0],) + x.shape[1:], dtype=dtype)], axis=0)\n",
    "           for x in data]\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd628a",
   "metadata": {},
   "source": [
    "### Generator\n",
    "Finally, we can plug the our functions into the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5daf8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    \n",
    "    # while True:\n",
    "    # while remainging > 0:\n",
    "    #    current_size = min(chunk_size, remaining)\n",
    "    Xs, ys, ts, names, header = read_timeseries(X_df, y_df)\n",
    "\n",
    "    Xs = process_batch(Xs, ts)\n",
    "    (Xs, ys, ts, names) = shuffle([Xs, ys, ts, names], batch_size)\n",
    "    current_size = len(Xs)\n",
    "\n",
    "    for i in range(0, current_size, batch_size):\n",
    "        X = make_sample_zeropadding(Xs[i:i + batch_size])\n",
    "        y = np.array(ys[i:i + batch_size])\n",
    "        batch_names = names[i:i+batch_size]\n",
    "        batch_ts = ts[i:i+batch_size]\n",
    "        batch_data = (X, y)\n",
    "        pdb.set_trace()\n",
    "        yield batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb06510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys, ts, names, header = read_timeseries(X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2454809b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator at 0x7fddb7df05f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = generator()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7fea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
