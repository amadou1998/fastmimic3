{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b239f1c1",
   "metadata": {},
   "source": [
    "# MIMIC-III: Concept-Drift and EHR for Linear Models\n",
    "\n",
    "The MIMIC-III database has been gathered between 2001 and 2012, at the Beth Israel Deaconess Medical Center.\n",
    "In 2008, the hospital switched the its electrical healt records (EHR) devices from the Carevue to Metavision system. This change reflects a more general phenomen: the constant update and morphing of care practices, which is reflected on the database as concept drift.\n",
    "\n",
    "This notebook will investigate the effect of this specific change in care practices on the predictive power of the models from the MIMIC-III benchmark. To do so, we will split the data by chartevents generated by the carevue and metavision system.\n",
    "\n",
    "We will begin by training the benchmark models with randomly picked subject and subsequently apply our split. \n",
    "We will evaluate the effect on the metrics of the models and additionally analysze the change in calibration charcteristics for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f0d2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from utils.mimic import get_sample_size\n",
    "\n",
    "import datasets.mimic\n",
    "from preprocessing.mimic import Preprocessor\n",
    "from preprocessing.feature_engineering import FeatureEngine\n",
    "from utils.mimic import Meter\n",
    "from utils.IO import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a46e0",
   "metadata": {},
   "source": [
    "## Running the Benchmark Models\n",
    "We will begin with the linear models for the sake of simplicity.\n",
    "\n",
    "The phontyping task needs the full dataset to make valid predictions, therefore we do not recomend using it here.\n",
    "\n",
    "### Load and Prepare the Data\n",
    "Next we load and preprocess the data for a given set into sample, label pairs which can directly be fed to a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "45275fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a task\n",
    "task = \"decompensation\" # length_of_stay, phenotyping, in_hospital_mortality, decompensation\n",
    "\n",
    "# Generate directories\n",
    "storage_path = Path(\"resources\", task)\n",
    "storage_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw_path = Path(storage_path / \"full_set\")\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logistic_path = Path(storage_path / \"logistic\" / \"full_set\")\n",
    "logistic_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "15859527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:17:22:datasets/mimic.py:L 51 - task data\n",
      "INFO - 2022-06-16 14:17:24:preprocessing/mimic.py:L 69 - Only type available for this task is binary! Argument disregarded\n"
     ]
    }
   ],
   "source": [
    "# Load the data into usable, subject-wise timeseries elements\n",
    "(timeseries,\n",
    " episodic_data,\n",
    " subject_events,\n",
    " subject_diagnoses,\n",
    " subject_icu_history) = datasets.mimic.load_data(storage_path=raw_path)\n",
    "\n",
    "# Load the configuration file for the preprocessor\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"datasets.json\")) as file:\n",
    "    config_dictionary = json.load(file)[\"mimic\"]\n",
    "\n",
    "# Preprocess the data for our task\n",
    "preprocessor = Preprocessor(timeseries,\n",
    "                            episodic_data,\n",
    "                            subject_diagnoses,\n",
    "                            subject_icu_history,\n",
    "                            config_dict=config_dictionary)\n",
    "\n",
    "X_subjects, y_subjects = preprocessor.make_task_data(task)\n",
    "\n",
    "# Load the configuration file for the feature engine\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"mimic\", \"channel_info.json\")) as channel_info_file:\n",
    "    channel_info = json.loads(channel_info_file.read())\n",
    "\n",
    "# Feature engineer, subsample and treat categorical data\n",
    "engine = FeatureEngine(channel_info, storage_path=logistic_path)\n",
    "\n",
    "(X_processed,\n",
    " y_processed,\n",
    " t_processed) = engine.transform(X_subjects, y_subjects)\n",
    "\n",
    "engine.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa3f91",
   "metadata": {},
   "source": [
    "### Splitting and Classical Preprocessing\n",
    "Next we can split the dataset and continue with imputing missing values and scaling the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "306cdd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:17:30:datasets/__init__.py:L 59 - Approximating test set size to 0.49995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/impute/_base.py:337: FutureWarning: The 'verbose' parameter was deprecated in version 1.1 and will be removed in 1.3. A warning will always be raised upon the removal of empty columns in the future version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "(X_train, X_test, y_train, y_test) = datasets.train_test_split(X_processed,\n",
    "                                                               y_processed,\n",
    "                                                               test_size= 0.5)\n",
    "\n",
    "# Impute missing data\n",
    "imputer = SimpleImputer(missing_values=np.nan,\n",
    "                        strategy='mean',\n",
    "                        verbose=0,\n",
    "                        copy=True)\n",
    "\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train = np.array(imputer.transform(X_train), dtype=np.float32)\n",
    "X_test = np.array(imputer.transform(X_test), dtype=np.float32)\n",
    "\n",
    "# Scale the samples\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a98b1d",
   "metadata": {},
   "source": [
    "### Making Predictions \n",
    "We can now begin by making predictions for the given task. First we need to load our standard settings, the we can make our prediction. The to make predictions is different for every task. Therefore you should only run the code for the task you ran the preprocessing for.\n",
    "\n",
    "**Common code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "80a9baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the configuration for our estimator\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"mimic\", \"model_config.json\")) as model_config_file:\n",
    "    model_config = json.loads(model_config_file.read())[\"logistic_regression\"][task]\n",
    "\n",
    "# Setting up a logistic regression estimator\n",
    "model = LogisticRegression(penalty=model_config[\"penalty\"],\n",
    "                           C=model_config[\"C\"],\n",
    "                           random_state=42,\n",
    "                           solver=model_config[\"solver\"],\n",
    "                           multi_class=model_config[\"multi_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90751b4",
   "metadata": {},
   "source": [
    "**Phenotyping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulitclass tasks\n",
    "multi_target_forest = MultiOutputClassifier(model, n_jobs=-1)\n",
    "multi_target_forest.fit(X_train, y_train)\n",
    "\n",
    "test_prediction = multi_target_forest.predict(X_test)\n",
    "train_prediction = multi_target_forest.predict(X_train)\n",
    "\n",
    "metrics = [\"auc-roc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a68ef",
   "metadata": {},
   "source": [
    "**Decompensation and In-hospital moratlity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f37f8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_prediction = model.predict(X_test)\n",
    "train_prediction = model.predict(X_train)\n",
    "\n",
    "metrics = [\"auc-roc\", \"accuracy\"]\n",
    "# metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9cc5c",
   "metadata": {},
   "source": [
    "**Length of stay prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulitclass tasks, different scores\n",
    "bins = config_dictionary['length_of_stay']['bins']\n",
    "\n",
    "y_train = np.digitize(y_train, bins)\n",
    "y_test = np.digitize(y_test, bins)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_prediction = model.predict(X_train)\n",
    "test_prediction = model.predict(X_test)\n",
    "\n",
    "metrics = [\"cohen_kappa\", \"mae\", \"mse\", \"confusion_matrix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8651d",
   "metadata": {},
   "source": [
    "### Compute Metrics\n",
    "Finally, we need to compte the performance of our model. The metrics are different for every task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa4b4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 62 - Train Set Metrics\n",
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 72 - AUC-ROC micro: 0.879127360896186\n",
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 79 - Accuracy: 0.974171164225135\n",
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 62 - Test Set Metrics\n",
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 72 - AUC-ROC micro: 0.4969104752480691\n",
      "INFO - 2022-06-16 14:19:44:utils/mimic.py:L 79 - Accuracy: 0.41873915558126085\n"
     ]
    }
   ],
   "source": [
    "meter = Meter()\n",
    "meter.print_metrics(train_prediction, y_train, metrics=metrics, title=\"Train Set\")\n",
    "meter.print_metrics(test_prediction, y_test, metrics=metrics, title=\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba995c4b",
   "metadata": {},
   "source": [
    "## Creating Concept Drift\n",
    "Now that we have our benchmark model ready, we can begin by investigating the concept drift, which is induced through the EHR switch. The first concern to make sure that the comparision is valid is to deduce the test set size and retrospectively align it for our benchmark. To do so, we will count the number of total available samples for the carevue system.\n",
    "\n",
    "We can load the carevue-only timeseries data by specifying the 'ehr' parameter with our load_data function. For subsequent variables, we will use the mv suffix for metavision samples and the cv suffix for carevue samples.\n",
    "\n",
    "### Preparing Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "20e1d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a task\n",
    "task = \"decompensation\" # length_of_stay, phenotyping, in_hospital_mortality, decompensation\n",
    "\n",
    "# Generate directories\n",
    "storage_path = Path(\"resources\", task)\n",
    "storage_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw_path_cv = Path(storage_path / \"carevue\")\n",
    "raw_path_mv = Path(storage_path / \"metavision\")\n",
    "raw_path_cv.mkdir(parents=True, exist_ok=True)\n",
    "raw_path_mv.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logistic_path_cv = Path(storage_path / \"logistic\" / \"carevue\")\n",
    "logistic_path_mv = Path(storage_path / \"logistic\" / \"metavision\")\n",
    "logistic_path_cv.mkdir(parents=True, exist_ok=True)\n",
    "logistic_path_mv.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "332aa8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:06:30:datasets/mimic.py:L 51 - task data\n",
      "INFO - 2022-06-16 14:06:32:preprocessing/mimic.py:L 69 - Only type available for this task is binary! Argument disregarded\n",
      "INFO - 2022-06-16 14:12:29:preprocessing/feature_engineering.py:L 104 - Samples processed: 5500\r"
     ]
    }
   ],
   "source": [
    "# Choose a task\n",
    "storage_path = Path(\"resources\", task)\n",
    "\n",
    "# Load the data into usable, subject-wise timeseries elements\n",
    "(timeseries_cv,\n",
    " episodic_data_cv,\n",
    " subject_events_cv,\n",
    " subject_diagnoses_cv,\n",
    " subject_icu_history_cv) = datasets.mimic.load_data(storage_path=raw_path_cv,\n",
    "                                                    ehr='carevue')\n",
    "\n",
    "# Load the configuration file for the preprocessor\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"datasets.json\")) as file:\n",
    "    config_dictionary = json.load(file)[\"mimic\"]\n",
    "\n",
    "# Preprocess the data for our task\n",
    "preprocessor = Preprocessor(timeseries_cv,\n",
    "                            episodic_data_cv,\n",
    "                            subject_diagnoses_cv,\n",
    "                            subject_icu_history_cv,\n",
    "                            config_dict=config_dictionary)\n",
    "\n",
    "X_subjects_cv, y_subjects_cv = preprocessor.make_task_data(task)\n",
    "\n",
    "# Load the configuration file for the feature engine\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"mimic\", \"channel_info.json\")) as channel_info_file:\n",
    "    channel_info = json.loads(channel_info_file.read())\n",
    "\n",
    "# Feature engineer, subsample and treat categorical data\n",
    "engine = FeatureEngine(channel_info, storage_path=logistic_path_cv)\n",
    "\n",
    "(X_processed_cv,\n",
    " y_processed_cv,\n",
    " t_processed_cv) = engine.transform(X_subjects_cv, y_subjects_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40e5fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:12:30:datasets/mimic.py:L 51 - task data\n",
      "INFO - 2022-06-16 14:12:32:preprocessing/mimic.py:L 69 - Only type available for this task is binary! Argument disregarded\n",
      "INFO - 2022-06-16 14:16:24:preprocessing/feature_engineering.py:L 104 - Samples processed: 4800\r"
     ]
    }
   ],
   "source": [
    "# Load the data into usable, subject-wise timeseries elements\n",
    "(timeseries_mv,\n",
    " episodic_data_mv,\n",
    " subject_events_mv,\n",
    " subject_diagnoses_mv,\n",
    " subject_icu_history_mv) = datasets.mimic.load_data(ehr=\"metavision\", storage_path=raw_path_mv)\n",
    "\n",
    "# Load the configuration file for the preprocessor\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"datasets.json\")) as file:\n",
    "    config_dictionary = json.load(file)[\"mimic\"]\n",
    "\n",
    "# Preprocess the data for our task\n",
    "preprocessor = Preprocessor(timeseries_mv,\n",
    "                            episodic_data_mv,\n",
    "                            subject_diagnoses_mv,\n",
    "                            subject_icu_history_mv,\n",
    "                            config_dict=config_dictionary)\n",
    "\n",
    "X_subjects_mv, y_subjects_mv = preprocessor.make_task_data(task)\n",
    "\n",
    "# Load the configuration file for the feature engine\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"mimic\", \"channel_info.json\")) as channel_info_file:\n",
    "    channel_info = json.loads(channel_info_file.read())\n",
    "\n",
    "# Feature engineer, subsample and treat categorical data\n",
    "engine = FeatureEngine(channel_info, storage_path=logistic_path_mv)\n",
    "\n",
    "(X_processed_mv,\n",
    " y_processed_mv,\n",
    " t_processed_mv) = engine.transform(X_subjects_mv, y_subjects_mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274bf5d",
   "metadata": {},
   "source": [
    "### Determining the Test Set Size\n",
    "Luckily our train_test_split function already set the requirement to count the total sample size of a subset of subjects. This functionality is implemented with the get_sample_size function which we imported previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3ce0f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = get_sample_size(X_processed_mv) / get_sample_size(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46929d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46795180722891566"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5c2be",
   "metadata": {},
   "source": [
    "### Finishing Data Preparation\n",
    "We can now repeat the data preprocessing setps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "222d8682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/impute/_base.py:337: FutureWarning: The 'verbose' parameter was deprecated in version 1.1 and will be removed in 1.3. A warning will always be raised upon the removal of empty columns in the future version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "X_train_cd = np.concatenate([*X_processed_cv.values()])\n",
    "y_train_cd = np.concatenate([*y_processed_cv.values()])\n",
    "X_test_cd = np.concatenate([*X_processed_mv.values()])\n",
    "y_test_cd = np.concatenate([*y_processed_mv.values()])\n",
    "\n",
    "# Impute missing data\n",
    "imputer = SimpleImputer(missing_values=np.nan,\n",
    "                        strategy='mean',\n",
    "                        verbose=0,\n",
    "                        copy=True)\n",
    "\n",
    "imputer.fit(X_train_cd)\n",
    "\n",
    "X_train_cd = np.array(imputer.transform(X_train_cd), dtype=np.float32)\n",
    "X_test_cd = np.array(imputer.transform(X_test_cd), dtype=np.float32)\n",
    "\n",
    "# Scale the samples\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_cd)\n",
    "\n",
    "X_train_cd = scaler.transform(X_train_cd)\n",
    "X_test_cd = scaler.transform(X_test_cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e43a09",
   "metadata": {},
   "source": [
    "**Common preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2bd69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the configuration for our estimator\n",
    "with open(Path(os.getenv(\"CONFIG\"), \"mimic\", \"model_config.json\")) as model_config_file:\n",
    "    model_config = json.loads(model_config_file.read())[\"logistic_regression\"][task]\n",
    "\n",
    "# Setting up a logistic regression estimator\n",
    "model_cd = LogisticRegression(penalty=model_config[\"penalty\"],\n",
    "                              C=model_config[\"C\"],\n",
    "                              random_state=42,\n",
    "                              solver=model_config[\"solver\"],\n",
    "                              multi_class=model_config[\"multi_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe5985",
   "metadata": {},
   "source": [
    "**Phenotyping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulitclass tasks\n",
    "multi_target_forest = MultiOutputClassifier(model_cd, n_jobs=-1)\n",
    "multi_target_forest.fit(X_train_cd, y_train_cd)\n",
    "\n",
    "test_prediction = multi_target_forest.predict(X_test_cd)\n",
    "train_prediction = multi_target_forest.predict(X_train_cd)\n",
    "\n",
    "metrics = [\"auc-roc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988326a",
   "metadata": {},
   "source": [
    "**Decompenstation and In-hospital mortality prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1d9ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cd.fit(X_train_cd, y_train_cd)\n",
    "\n",
    "test_prediction = model_cd.predict(X_test_cd)\n",
    "train_prediction = model_cd.predict(X_train_cd)\n",
    "\n",
    "metrics = [\"auc-roc\", \"accuracy\"]\n",
    "# metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d46c57",
   "metadata": {},
   "source": [
    "**Length of Stay Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulitclass tasks, different scores\n",
    "bins = config_dictionary['length_of_stay']['bins']\n",
    "\n",
    "y_train_cd = np.digitize(y_train_cd, bins)\n",
    "y_test_cd = np.digitize(y_test_cd, bins)\n",
    "\n",
    "model_cd.fit(X_train_cd, y_train_cd)\n",
    "\n",
    "train_prediction = model_cd.predict(X_train_cd)\n",
    "test_prediction = model_cd.predict(X_test_cd)\n",
    "\n",
    "metrics = [\"cohen_kappa\", \"mae\", \"mse\", \"confusion_matrix\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3d0e7",
   "metadata": {},
   "source": [
    "### Compute Metrics\n",
    "Finally, we need to compte the performance of our model. The metrics are different for every task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f02d2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 62 - Train Set Metrics\n",
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 72 - AUC-ROC micro: 0.9293632748389241\n",
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 79 - Accuracy: 0.9884057971014493\n",
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 62 - Test Set Metrics\n",
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 72 - AUC-ROC micro: 0.49054809791872045\n",
      "INFO - 2022-06-16 14:16:29:utils/mimic.py:L 79 - Accuracy: 0.6249227600411946\n"
     ]
    }
   ],
   "source": [
    "meter = Meter()\n",
    "meter.print_metrics(train_prediction, y_train_cd, metrics=metrics, title=\"Train Set\")\n",
    "meter.print_metrics(test_prediction, y_test_cd, metrics=metrics, title=\"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48203fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
