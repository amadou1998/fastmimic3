{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading Pandas\n",
    "\n",
    "In this notebook we are going to demonstrate the mutliprocessing_pandas functionality form the utils module. \n",
    "\n",
    "To do so we will concatenate our training dataframe iteratively to a bigger frame. Lets begin by importing our modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import datetime\n",
    "import dateutil\n",
    "from importlib import reload\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pdb\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# The docker environment manipulates the python path to include our source directory\n",
    "# Execute this from within the docker environ to make these import work\n",
    "import utils\n",
    "import datasets.smartmeter as smartmeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Massive DataFrame\n",
    "\n",
    "Now we generate the larger dataframe, by simply repeating the sample training dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>2012-10-12 00:30:00.0000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>2012-10-12 01:00:00.0000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>2012-10-12 01:30:00.0000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>2012-10-12 02:00:00.0000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000002</td>\n",
       "      <td>2012-10-12 02:30:00.0000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp energy(kWh/hh)\n",
       "0  MAC000002  2012-10-12 00:30:00.0000000             0 \n",
       "1  MAC000002  2012-10-12 01:00:00.0000000             0 \n",
       "2  MAC000002  2012-10-12 01:30:00.0000000             0 \n",
       "3  MAC000002  2012-10-12 02:00:00.0000000             0 \n",
       "4  MAC000002  2012-10-12 02:30:00.0000000             0 "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = Path(os.getenv(\"DATA\"), \"smart-meter-london\")\n",
    "data_df = pd.read_csv(Path(dataset_folder, \"halfhourly_dataset\", \"halfhourly_dataset\", \"block_0.csv\"), low_memory=False)\n",
    "massive_df = pd.concat([data_df] * 2) \n",
    "\n",
    "# Lets look at the result\n",
    "print(len(massive_df))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 15 million samples, the execution time should be slow enough to notice the execution times. \n",
    "Lets define a simple function by which we are going to benchmark the speed of our multicored approach.\n",
    "\n",
    "## II. Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use the cast to datetime obj function, which we use quite frequently\n",
    "def convert_time(x):\n",
    "    return dateutil.parser.parse(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look how long this function will take when processing the dataframe with help of the apply method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.14152312278748\n"
     ]
    }
   ],
   "source": [
    "# start measuring\n",
    "start = time.time()\n",
    "# execute \n",
    "slow_df = massive_df['tstp'].apply(convert_time)\n",
    "# end measuring\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Concurrent Processing\n",
    "\n",
    "We are going to use the concurrent library with its ProcessorPoolExecutor class as oposed to multiprocessing.pool, as the complexity of our application is relatively high and we therefore prefer customizability. \n",
    "\n",
    "Lets begin by importing the concurent module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets define the positional arguments.\n",
    "\n",
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = 'apply'            # we are going to use the getattr buildin which requires a string\n",
    "args = [convert_time]                 # positional argument to apply but to keep the option for mor open we make it a list\n",
    "kwargs = {}                 # the apply function does not take any for series\n",
    "max_cores = 10                # in case we do not wont to allocate all the compute power\n",
    "data_df = massive_df['tstp'].copy()   # we dont want any referencing accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets convert those positional arguments into usable values for our concurrent.future.Proc. We need to split the dataframe, so that we can treat the sections independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not maxcores take all of them!!\n",
    "if max_cores:\n",
    "    n_cores = np.min([max_cores, psutil.cpu_count()]) - 2\n",
    "else:\n",
    "    n_cores = psutil.cpu_count() - 2\n",
    "    \n",
    "# very easy way to split the array\n",
    "split_array = np.array_split(data_df, n_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get to the multithreading part. This is where it get interesting, therefore we will measure the time. \n",
    "\n",
    "!!The following code will not run due to the ipynb kernels limitation!! \n",
    "!!Import from utils instead!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start timer\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "futures = list()          # processes list\n",
    "return_values = list()    # result partial df list\n",
    "\n",
    "# The following line creates an atomic block, finishing only after we are done with each process \n",
    "# and destroying executor on the go\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    # Iteratively create processes for array elements\n",
    "\n",
    "    for index, array in enumerate(split_array):\n",
    "        # If string interprete ass dataframe member\n",
    "        if isinstance(function, str):\n",
    "            func = getattr(array, function)\n",
    "            futures.append(executor.submit(func, *args.copy(), **kwargs.copy()))\n",
    "        else:\n",
    "            futures.append(executor.submit(function, array, *args.copy(), **kwargs.copy()))\n",
    "\n",
    "\n",
    "# Now lets retrieve the results \n",
    "for process in futures:\n",
    "    return_value = process.result()\n",
    "    return_values.append(return_value)\n",
    "\n",
    "for index, process in enumerate(futures):\n",
    "\n",
    "    return_value = process.result()\n",
    "    return_values.append(return_value)\n",
    "result_df = pd.concat(return_values)\n",
    "if len(result_df) == len(data_df):\n",
    "    result_df = result_df.reindex(index = data_df.index)\n",
    "else:\n",
    "    result_df.index = range(0, len(result_df))\n",
    "end = time.time()\n",
    "\n",
    "# and concatenate to our result data frame\n",
    "final_df = pd.concat(return_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality is also implemented with the utils module. Lets call it that way and measure the execution speed aswell as compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multithreading needed 25.73172116279602\n"
     ]
    }
   ],
   "source": [
    "print(f\"multithreading needed {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_df.equals(slow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">\n",
      "> M: Multiprocessing --------------\n",
      "\u001b[K> M: Creating processes\u001b[K\u001b[?25h\n",
      "\u001b[K> M: Running processesg\u001b[K\u001b[K\n",
      "\u001b[K> M: Duration: 22.76 sec ----------\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "reload(utils)\n",
    "start = time.time()\n",
    "fast_df = utils.pandas.multiprocess(data_df, function, args=args)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_df.equals(slow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! Results are equivalent. We can now have a look at the timing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a third of the time required for a single processor. Note that this ratio decreases further with increasing sample size.\n",
    "\n",
    "## IV. Row Interdependency\n",
    "\n",
    "Some functions have so called row interdependencies, such as the diff method. The diff method needs the value of the preceiding row to compute the current row. When splitting the dataframe into an array of frames, this creates several nan values. To aliviate this issue we are going to implement an overlap function using the example from [stackoverflow](https://stackoverflow.com/questions/55964768/split-data-frames-into-multiple-with-overlap-rows).\n",
    "\n",
    "The idea is to have the dataframe splits overlap each other, so that the rows overhanging rows can be used for the computation and then discarded before the concatnation. \n",
    "\n",
    "The dataframes with overhang need to look like: ![](./pics/dataframe-overlapsplit.png)\n",
    "\n",
    "The dataframe from the example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ID': [178,153,193,195,214,157,205,212,219,166,217,186,170,207,204,201,179,215,213,170,217,199], \n",
    "'Unit_Weight': [178,153,193,195,214,157,205,212,219,166,217,186,170,207,204,201,179,215,213,170,217,199]}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Prameters\n",
    "\n",
    "We will want to use the input parameters:\n",
    "- sections: # of dataframe splits\n",
    "- overlap: overlap depth between two frames (must be multiple of 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = 5\n",
    "overlap = 2  # in utils we will use row_depedencies = 1 to say the \n",
    "             # row is dependent on its direct neighbourhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the overlapping block from our input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed blocks:\n",
      "    ID  Unit_Weight\n",
      "0  178          178\n",
      "1  153          153\n",
      "2  193          193\n",
      "3  195          195\n",
      "4  214          214\n",
      "5  157          157\n",
      "    ID  Unit_Weight\n",
      "4  214          214\n",
      "5  157          157\n",
      "6  205          205\n",
      "7  212          212\n",
      "8  219          219\n",
      "9  166          166\n",
      "     ID  Unit_Weight\n",
      "8   219          219\n",
      "9   166          166\n",
      "10  217          217\n",
      "11  186          186\n",
      "12  170          170\n",
      "13  207          207\n",
      "     ID  Unit_Weight\n",
      "12  170          170\n",
      "13  207          207\n",
      "14  204          204\n",
      "15  201          201\n",
      "16  179          179\n",
      "17  215          215\n",
      "     ID  Unit_Weight\n",
      "16  179          179\n",
      "17  215          215\n",
      "18  213          213\n",
      "19  170          170\n",
      "20  217          217\n",
      "21  199          199\n"
     ]
    }
   ],
   "source": [
    "blockl_clean = (len(df)-overlap)/sections       # block length without the overlap\n",
    "blockl_overlap = int(blockl_clean + overlap)    # block length with overlap\n",
    "\n",
    "# The blocks can be easily created using list comprehension\n",
    "block_array = [df.loc[n_block:n_block + blockl_overlap - 1, :] for n_block in range(0, len(df),blockl_overlap - overlap) if n_block < len(df) - overlap]\n",
    "\n",
    "# Lets output them, so that we can check \n",
    "print(\"Unprocessed blocks:\")\n",
    "for block_overlap in block_array:\n",
    "    print (block_overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets process them and put them back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Unit_Weight\n",
      "1 -25.0        -25.0\n",
      "2  40.0         40.0\n",
      "3   2.0          2.0\n",
      "4  19.0         19.0\n",
      "     ID  Unit_Weight\n",
      "5 -57.0        -57.0\n",
      "6  48.0         48.0\n",
      "7   7.0          7.0\n",
      "8   7.0          7.0\n",
      "      ID  Unit_Weight\n",
      "9  -53.0        -53.0\n",
      "10  51.0         51.0\n",
      "11 -31.0        -31.0\n",
      "12 -16.0        -16.0\n",
      "      ID  Unit_Weight\n",
      "13  37.0         37.0\n",
      "14  -3.0         -3.0\n",
      "15  -3.0         -3.0\n",
      "16 -22.0        -22.0\n",
      "      ID  Unit_Weight\n",
      "17  36.0         36.0\n",
      "18  -2.0         -2.0\n",
      "19 -43.0        -43.0\n",
      "20  47.0         47.0\n",
      "21 -18.0        -18.0\n",
      "The block is equal to the original: True\n"
     ]
    }
   ],
   "source": [
    "# Now lets put them together    \n",
    "processed_blocks = list()\n",
    "truncate = int(overlap/2)\n",
    "\n",
    "for index, block in enumerate(block_array):\n",
    "    # Call the function on each block\n",
    "    block = block.diff()\n",
    "    \n",
    "    # Then remove the overlap exept for the last\n",
    "    if index == len(block_array) - 1:\n",
    "        block = block.iloc[truncate:]\n",
    "    else:\n",
    "        block = block.iloc[truncate:-truncate]\n",
    "    print(block)\n",
    "    processed_blocks.append(block)\n",
    "\n",
    "    \n",
    "result_df = pd.concat(processed_blocks)\n",
    "result_df = result_df.reindex(index = df.index)\n",
    "print(f\"The block is equal to the original: {result_df.equals(df.diff())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets finally recreate this using the utils module. The previously seen split function can be implored through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = utils.pandas.overlap_split(df, 5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire multithreaded operation can be recreated using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">\n",
      "> M: Multiprocessing --------------\n",
      "\u001b[K> M: Creating processes\u001b[K\u001b[?25h\n",
      "\u001b[K> M: Running processesg\u001b[K\u001b[K\n",
      "\u001b[K> M: Duration: 0.51 sec -----------\n",
      ">\n",
      "The block is equal to the original: False\n"
     ]
    }
   ],
   "source": [
    "reload(utils)\n",
    "result_df = utils.pandas.multiprocess(df, 'diff', row_interdependency=1, max_cores=5)\n",
    "print(f\"The block is equal to the original: {result_df.equals(df.diff())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Unit_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-57.0</td>\n",
       "      <td>-57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-53.0</td>\n",
       "      <td>-53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-31.0</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-18.0</td>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Unit_Weight\n",
       "0  -25.0        -25.0\n",
       "1   40.0         40.0\n",
       "2    2.0          2.0\n",
       "3   19.0         19.0\n",
       "4  -57.0        -57.0\n",
       "5   48.0         48.0\n",
       "6    7.0          7.0\n",
       "7    7.0          7.0\n",
       "8  -53.0        -53.0\n",
       "9   51.0         51.0\n",
       "10 -31.0        -31.0\n",
       "11 -16.0        -16.0\n",
       "12  37.0         37.0\n",
       "13  -3.0         -3.0\n",
       "14  -3.0         -3.0\n",
       "15 -22.0        -22.0\n",
       "16  36.0         36.0\n",
       "17  -2.0         -2.0\n",
       "18 -43.0        -43.0\n",
       "19  47.0         47.0\n",
       "20 -18.0        -18.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Unit_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-57.0</td>\n",
       "      <td>-57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-53.0</td>\n",
       "      <td>-53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-31.0</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-18.0</td>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Unit_Weight\n",
       "0    NaN          NaN\n",
       "1  -25.0        -25.0\n",
       "2   40.0         40.0\n",
       "3    2.0          2.0\n",
       "4   19.0         19.0\n",
       "5  -57.0        -57.0\n",
       "6   48.0         48.0\n",
       "7    7.0          7.0\n",
       "8    7.0          7.0\n",
       "9  -53.0        -53.0\n",
       "10  51.0         51.0\n",
       "11 -31.0        -31.0\n",
       "12 -16.0        -16.0\n",
       "13  37.0         37.0\n",
       "14  -3.0         -3.0\n",
       "15  -3.0         -3.0\n",
       "16 -22.0        -22.0\n",
       "17  36.0         36.0\n",
       "18  -2.0         -2.0\n",
       "19 -43.0        -43.0\n",
       "20  47.0         47.0\n",
       "21 -18.0        -18.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I changed this whole reindexing stuff for something in the load_data function but i cant remember\n",
    "### I need to write unittests for all this stuff its overwhelming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
